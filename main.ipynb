{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzip Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./creditcardfraud.zip', 'r') as f:\n",
    "    f.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.694241</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672771</td>\n",
       "      <td>0.973364</td>\n",
       "      <td>-0.245116</td>\n",
       "      <td>0.347067</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.331127</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330891</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608495</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316522</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>-0.232494</td>\n",
       "      <td>-0.153349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307376</td>\n",
       "      <td>-0.880075</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561130</td>\n",
       "      <td>0.320693</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>-0.342474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.693499</td>\n",
       "      <td>-0.811576</td>\n",
       "      <td>1.169466</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364571</td>\n",
       "      <td>1.351451</td>\n",
       "      <td>0.639775</td>\n",
       "      <td>0.207372</td>\n",
       "      <td>-1.378673</td>\n",
       "      <td>0.190699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337631</td>\n",
       "      <td>1.063356</td>\n",
       "      <td>1.456317</td>\n",
       "      <td>-1.138090</td>\n",
       "      <td>-0.628536</td>\n",
       "      <td>-0.288446</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.493324</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182514</td>\n",
       "      <td>-0.609726</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936148</td>\n",
       "      <td>0.192070</td>\n",
       "      <td>0.316017</td>\n",
       "      <td>-1.262501</td>\n",
       "      <td>-0.050468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304776</td>\n",
       "      <td>-1.941024</td>\n",
       "      <td>1.241902</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186188</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.591329</td>\n",
       "      <td>0.531540</td>\n",
       "      <td>1.021410</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071998</td>\n",
       "      <td>0.479301</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>0.744325</td>\n",
       "      <td>0.691624</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100009</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395201</td>\n",
       "      <td>1.041609</td>\n",
       "      <td>0.543619</td>\n",
       "      <td>0.651815</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.694241 -0.044075  1.672771  0.973364 -0.245116  0.347067  0.193679   \n",
       "1  0.608495  0.161176  0.109797  0.316522  0.043483 -0.061820 -0.063700   \n",
       "2 -0.693499 -0.811576  1.169466  0.268231 -0.364571  1.351451  0.639775   \n",
       "3 -0.493324 -0.112169  1.182514 -0.609726 -0.007469  0.936148  0.192070   \n",
       "4 -0.591329  0.531540  1.021410  0.284655 -0.295015  0.071998  0.479301   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.082637  0.331127  0.083385  ... -0.024923  0.382854 -0.176911  0.110507   \n",
       "1  0.071253 -0.232494 -0.153349  ... -0.307376 -0.880075  0.162201 -0.561130   \n",
       "2  0.207372 -1.378673  0.190699  ...  0.337631  1.063356  1.456317 -1.138090   \n",
       "3  0.316017 -1.262501 -0.050468  ... -0.147443  0.007267 -0.304776 -1.941024   \n",
       "4 -0.226510  0.744325  0.691624  ... -0.012839  1.100009 -0.220123  0.233250   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.246585 -0.392170  0.330891 -0.063781  0.244964      0  \n",
       "1  0.320693  0.261069 -0.022256  0.044607 -0.342474      0  \n",
       "2 -0.628536 -0.288446 -0.137137 -0.181021  1.160684      0  \n",
       "3  1.241902 -0.460217  0.155396  0.186188  0.140534      0  \n",
       "4 -0.395201  1.041609  0.543619  0.651815 -0.073403      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop(columns='Time')\n",
    "\n",
    "df.iloc[:, :-1] = (df.iloc[:, :-1] - df.iloc[:, :-1].mean()) / df.iloc[:, :-1].std()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.407479e-15</td>\n",
       "      <td>-1.516852e-16</td>\n",
       "      <td>4.879472e-15</td>\n",
       "      <td>-4.845942e-16</td>\n",
       "      <td>1.868921e-15</td>\n",
       "      <td>-3.879947e-16</td>\n",
       "      <td>9.288721e-16</td>\n",
       "      <td>2.476859e-16</td>\n",
       "      <td>6.584334e-16</td>\n",
       "      <td>4.274129e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>8.981359e-19</td>\n",
       "      <td>-1.591098e-15</td>\n",
       "      <td>-4.418829e-16</td>\n",
       "      <td>4.390887e-17</td>\n",
       "      <td>-1.757951e-15</td>\n",
       "      <td>-2.815406e-17</td>\n",
       "      <td>2.532244e-18</td>\n",
       "      <td>-8.781773e-18</td>\n",
       "      <td>2.308662e-13</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.879850e+01</td>\n",
       "      <td>-4.403521e+01</td>\n",
       "      <td>-3.187168e+01</td>\n",
       "      <td>-4.013912e+00</td>\n",
       "      <td>-8.240795e+01</td>\n",
       "      <td>-1.963602e+01</td>\n",
       "      <td>-3.520933e+01</td>\n",
       "      <td>-6.130242e+01</td>\n",
       "      <td>-1.222799e+01</td>\n",
       "      <td>-2.258187e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.741898e+01</td>\n",
       "      <td>-1.506562e+01</td>\n",
       "      <td>-7.175434e+01</td>\n",
       "      <td>-4.683630e+00</td>\n",
       "      <td>-1.975030e+01</td>\n",
       "      <td>-5.401088e+00</td>\n",
       "      <td>-5.590650e+01</td>\n",
       "      <td>-4.674604e+01</td>\n",
       "      <td>-3.532288e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.698909e-01</td>\n",
       "      <td>-3.624701e-01</td>\n",
       "      <td>-5.872131e-01</td>\n",
       "      <td>-5.993777e-01</td>\n",
       "      <td>-5.010677e-01</td>\n",
       "      <td>-5.766811e-01</td>\n",
       "      <td>-4.478852e-01</td>\n",
       "      <td>-1.746801e-01</td>\n",
       "      <td>-5.853621e-01</td>\n",
       "      <td>-4.917352e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.109428e-01</td>\n",
       "      <td>-7.473463e-01</td>\n",
       "      <td>-2.591780e-01</td>\n",
       "      <td>-5.854666e-01</td>\n",
       "      <td>-6.083990e-01</td>\n",
       "      <td>-6.780705e-01</td>\n",
       "      <td>-1.755050e-01</td>\n",
       "      <td>-1.604437e-01</td>\n",
       "      <td>-3.308395e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.245335e-03</td>\n",
       "      <td>3.965677e-02</td>\n",
       "      <td>1.186122e-01</td>\n",
       "      <td>-1.401721e-02</td>\n",
       "      <td>-3.936675e-02</td>\n",
       "      <td>-2.058043e-01</td>\n",
       "      <td>3.241718e-02</td>\n",
       "      <td>1.871979e-02</td>\n",
       "      <td>-4.681161e-02</td>\n",
       "      <td>-8.533536e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.009422e-02</td>\n",
       "      <td>9.345360e-03</td>\n",
       "      <td>-1.792417e-02</td>\n",
       "      <td>6.765666e-02</td>\n",
       "      <td>3.183234e-02</td>\n",
       "      <td>-1.081215e-01</td>\n",
       "      <td>3.325168e-03</td>\n",
       "      <td>3.406362e-02</td>\n",
       "      <td>-2.652710e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.716927e-01</td>\n",
       "      <td>4.867194e-01</td>\n",
       "      <td>6.774557e-01</td>\n",
       "      <td>5.250073e-01</td>\n",
       "      <td>4.433457e-01</td>\n",
       "      <td>2.991620e-01</td>\n",
       "      <td>4.611099e-01</td>\n",
       "      <td>2.740780e-01</td>\n",
       "      <td>5.435296e-01</td>\n",
       "      <td>4.168834e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.537387e-01</td>\n",
       "      <td>7.283347e-01</td>\n",
       "      <td>2.364315e-01</td>\n",
       "      <td>7.257141e-01</td>\n",
       "      <td>6.727994e-01</td>\n",
       "      <td>4.996654e-01</td>\n",
       "      <td>2.255644e-01</td>\n",
       "      <td>2.371521e-01</td>\n",
       "      <td>-4.471699e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.253349e+00</td>\n",
       "      <td>1.335773e+01</td>\n",
       "      <td>6.187982e+00</td>\n",
       "      <td>1.191872e+01</td>\n",
       "      <td>2.521409e+01</td>\n",
       "      <td>5.502005e+01</td>\n",
       "      <td>9.747807e+01</td>\n",
       "      <td>1.675150e+01</td>\n",
       "      <td>1.419492e+01</td>\n",
       "      <td>2.180754e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.703465e+01</td>\n",
       "      <td>1.447302e+01</td>\n",
       "      <td>3.607661e+01</td>\n",
       "      <td>7.569671e+00</td>\n",
       "      <td>1.442529e+01</td>\n",
       "      <td>7.293962e+00</td>\n",
       "      <td>7.831926e+01</td>\n",
       "      <td>1.025432e+02</td>\n",
       "      <td>1.023621e+02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.407479e-15 -1.516852e-16  4.879472e-15 -4.845942e-16  1.868921e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.879850e+01 -4.403521e+01 -3.187168e+01 -4.013912e+00 -8.240795e+01   \n",
       "25%   -4.698909e-01 -3.624701e-01 -5.872131e-01 -5.993777e-01 -5.010677e-01   \n",
       "50%    9.245335e-03  3.965677e-02  1.186122e-01 -1.401721e-02 -3.936675e-02   \n",
       "75%    6.716927e-01  4.867194e-01  6.774557e-01  5.250073e-01  4.433457e-01   \n",
       "max    1.253349e+00  1.335773e+01  6.187982e+00  1.191872e+01  2.521409e+01   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -3.879947e-16  9.288721e-16  2.476859e-16  6.584334e-16  4.274129e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.963602e+01 -3.520933e+01 -6.130242e+01 -1.222799e+01 -2.258187e+01   \n",
       "25%   -5.766811e-01 -4.478852e-01 -1.746801e-01 -5.853621e-01 -4.917352e-01   \n",
       "50%   -2.058043e-01  3.241718e-02  1.871979e-02 -4.681161e-02 -8.533536e-02   \n",
       "75%    2.991620e-01  4.611099e-01  2.740780e-01  5.435296e-01  4.168834e-01   \n",
       "max    5.502005e+01  9.747807e+01  1.675150e+01  1.419492e+01  2.180754e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  8.981359e-19 -1.591098e-15 -4.418829e-16  4.390887e-17   \n",
       "std    ...  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min    ... -4.741898e+01 -1.506562e+01 -7.175434e+01 -4.683630e+00   \n",
       "25%    ... -3.109428e-01 -7.473463e-01 -2.591780e-01 -5.854666e-01   \n",
       "50%    ... -4.009422e-02  9.345360e-03 -1.792417e-02  6.765666e-02   \n",
       "75%    ...  2.537387e-01  7.283347e-01  2.364315e-01  7.257141e-01   \n",
       "max    ...  3.703465e+01  1.447302e+01  3.607661e+01  7.569671e+00   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.757951e-15 -2.815406e-17  2.532244e-18 -8.781773e-18  2.308662e-13   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.975030e+01 -5.401088e+00 -5.590650e+01 -4.674604e+01 -3.532288e-01   \n",
       "25%   -6.083990e-01 -6.780705e-01 -1.755050e-01 -1.604437e-01 -3.308395e-01   \n",
       "50%    3.183234e-02 -1.081215e-01  3.325168e-03  3.406362e-02 -2.652710e-01   \n",
       "75%    6.727994e-01  4.996654e-01  2.255644e-01  2.371521e-01 -4.471699e-02   \n",
       "max    1.442529e+01  7.293962e+00  7.831926e+01  1.025432e+02  1.023621e+02   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.848070e+05\n",
       "mean     2.308662e-13\n",
       "std      1.000000e+00\n",
       "min     -3.532288e-01\n",
       "25%     -3.308395e-01\n",
       "50%     -2.652710e-01\n",
       "75%     -4.471699e-02\n",
       "max      1.023621e+02\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Transaction Array shape: (492, 30)\n",
      "Non-Fraud Transaction Array shape: (284315, 30)\n"
     ]
    }
   ],
   "source": [
    "fraud_transactions = df[df.Class == 1]\n",
    "fraud_transactions_array = fraud_transactions.to_numpy()\n",
    "print(\"Fraud Transaction Array shape:\", fraud_transactions_array.shape)\n",
    "\n",
    "non_fraud_transactions = df[df.Class == 0]\n",
    "non_fraud_transactions_array = non_fraud_transactions.to_numpy()\n",
    "print(\"Non-Fraud Transaction Array shape:\", non_fraud_transactions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Non-Fraud samples shape: (508, 30)\n"
     ]
    }
   ],
   "source": [
    "non_fraud = non_fraud_transactions_array[:508]\n",
    "\n",
    "print(\"Train Non-Fraud samples shape:\", non_fraud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.concatenate((fraud_transactions_array, non_fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train shape: (1000, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total train shape:\", Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (900, 29)\n",
      "y train shape: (900,)\n",
      "\n",
      "X test shape: (100, 29)\n",
      "y test shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(Data)\n",
    "\n",
    "x_train = Data[:math.floor(train_test_ratio * len(Data))][:, :29]\n",
    "y_train = Data[:math.floor(train_test_ratio * len(Data))][:, 29]\n",
    "\n",
    "x_test = Data[math.floor(train_test_ratio * len(Data)):][:, :29]\n",
    "y_test = Data[math.floor(train_test_ratio * len(Data)):][:, 29]\n",
    "\n",
    "print(\"X train shape:\", x_train.shape)\n",
    "print(\"y train shape:\", y_train.shape)\n",
    "print()\n",
    "print(\"X test shape:\", x_test.shape)\n",
    "print(\"y test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(y, threshold=0.5):\n",
    "    new_y = []\n",
    "    for x in y:\n",
    "        if x >= threshold:\n",
    "            new_y.append(float(1.))\n",
    "        else:\n",
    "            new_y.append(float(0.))\n",
    "    return np.asarray(new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_clf = LinearRegression(fit_intercept=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_clf.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = linear_regression_clf.predict(X=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = classify(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear Regression] --> Accuracy over validation set: 0.67\n"
     ]
    }
   ],
   "source": [
    "true_guesses = np.sum(y_predict == y_test)\n",
    "accuracy_over_validation_set = true_guesses / len(y_test)\n",
    "print(\"[Linear Regression] --> Accuracy over validation set:\", accuracy_over_validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_clf = LogisticRegression(verbose=1, penalty='l2', max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "history = logistic_regression_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = logistic_regression_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = classify(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Logistic Regression] --> Accuracy over validation set: 0.87\n"
     ]
    }
   ],
   "source": [
    "true_guesses = np.sum(y_predict == y_test)\n",
    "accuracy_over_validation_set = true_guesses / len(y_test)\n",
    "print(\"[Logistic Regression] --> Accuracy over validation set:\", accuracy_over_validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_clf = LinearSVC(penalty='l2', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farzam/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "history = linear_svc_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = linear_svc_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear SVC] --> Accuracy over validation set: 0.91\n"
     ]
    }
   ],
   "source": [
    "true_guesses = np.sum(y_predict == y_test)\n",
    "accuracy_over_validation_set = true_guesses / len(y_test)\n",
    "print(\"[Linear SVC] --> Accuracy over validation set:\", accuracy_over_validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC\n",
    "* We use [Radial Basis Function (RBF) kernel SVM](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html) as kernel to classify our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = SVC(kernel='rbf', gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = svc_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = svc_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVC with BRF kernel] --> Accuracy over validation set: 0.93\n"
     ]
    }
   ],
   "source": [
    "true_guesses = np.sum(y_predict == y_test)\n",
    "accuracy_over_validation_set = true_guesses / len(y_test)\n",
    "print(\"[SVC with BRF kernel] --> Accuracy over validation set:\", accuracy_over_validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Dense(16, activation='relu', kernel_regularizer=l2(0.005)),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=l2(0.005)),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model.compile(tf.keras.optimizers.SGD(0.005), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "900/900 [==============================] - 1s 1ms/sample - loss: 1.1223 - acc: 0.3067 - val_loss: 0.9366 - val_acc: 0.5400\n",
      "Epoch 2/500\n",
      "900/900 [==============================] - 0s 281us/sample - loss: 0.9440 - acc: 0.6744 - val_loss: 0.9078 - val_acc: 0.6600\n",
      "Epoch 3/500\n",
      "900/900 [==============================] - 0s 194us/sample - loss: 0.8913 - acc: 0.7933 - val_loss: 0.8934 - val_acc: 0.5900\n",
      "Epoch 4/500\n",
      "900/900 [==============================] - 0s 298us/sample - loss: 0.8535 - acc: 0.8311 - val_loss: 0.8835 - val_acc: 0.5700\n",
      "Epoch 5/500\n",
      "900/900 [==============================] - 0s 237us/sample - loss: 0.8216 - acc: 0.8522 - val_loss: 0.8743 - val_acc: 0.5500\n",
      "Epoch 6/500\n",
      "900/900 [==============================] - 0s 279us/sample - loss: 0.7880 - acc: 0.8633 - val_loss: 0.8600 - val_acc: 0.5500\n",
      "Epoch 7/500\n",
      "900/900 [==============================] - 0s 287us/sample - loss: 0.7428 - acc: 0.8689 - val_loss: 0.8336 - val_acc: 0.5700\n",
      "Epoch 8/500\n",
      "900/900 [==============================] - 0s 225us/sample - loss: 0.6750 - acc: 0.8800 - val_loss: 0.7932 - val_acc: 0.5700\n",
      "Epoch 9/500\n",
      "900/900 [==============================] - 0s 213us/sample - loss: 0.5958 - acc: 0.8811 - val_loss: 0.7552 - val_acc: 0.5600\n",
      "Epoch 10/500\n",
      "900/900 [==============================] - 0s 232us/sample - loss: 0.5319 - acc: 0.8811 - val_loss: 0.7277 - val_acc: 0.5500\n",
      "Epoch 11/500\n",
      "900/900 [==============================] - 0s 180us/sample - loss: 0.4888 - acc: 0.8778 - val_loss: 0.7142 - val_acc: 0.5500\n",
      "Epoch 12/500\n",
      "900/900 [==============================] - 0s 107us/sample - loss: 0.4636 - acc: 0.8778 - val_loss: 0.7072 - val_acc: 0.5500\n",
      "Epoch 13/500\n",
      "900/900 [==============================] - 0s 188us/sample - loss: 0.4477 - acc: 0.8778 - val_loss: 0.7032 - val_acc: 0.5500\n",
      "Epoch 14/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.4366 - acc: 0.8778 - val_loss: 0.7010 - val_acc: 0.5500\n",
      "Epoch 15/500\n",
      "900/900 [==============================] - 0s 257us/sample - loss: 0.4287 - acc: 0.8778 - val_loss: 0.6990 - val_acc: 0.5500\n",
      "Epoch 16/500\n",
      "900/900 [==============================] - 0s 205us/sample - loss: 0.4229 - acc: 0.8778 - val_loss: 0.6980 - val_acc: 0.5500\n",
      "Epoch 17/500\n",
      "900/900 [==============================] - 0s 220us/sample - loss: 0.4178 - acc: 0.8778 - val_loss: 0.6963 - val_acc: 0.5500\n",
      "Epoch 18/500\n",
      "900/900 [==============================] - 0s 209us/sample - loss: 0.4133 - acc: 0.8778 - val_loss: 0.6959 - val_acc: 0.5500\n",
      "Epoch 19/500\n",
      "900/900 [==============================] - 0s 219us/sample - loss: 0.4088 - acc: 0.8778 - val_loss: 0.6951 - val_acc: 0.5500\n",
      "Epoch 20/500\n",
      "900/900 [==============================] - 0s 230us/sample - loss: 0.4049 - acc: 0.8778 - val_loss: 0.6941 - val_acc: 0.5500\n",
      "Epoch 21/500\n",
      "900/900 [==============================] - 0s 225us/sample - loss: 0.4014 - acc: 0.8778 - val_loss: 0.6922 - val_acc: 0.5500\n",
      "Epoch 22/500\n",
      "900/900 [==============================] - 0s 200us/sample - loss: 0.3984 - acc: 0.8778 - val_loss: 0.6915 - val_acc: 0.5500\n",
      "Epoch 23/500\n",
      "900/900 [==============================] - 0s 182us/sample - loss: 0.3953 - acc: 0.8778 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 24/500\n",
      "900/900 [==============================] - 0s 191us/sample - loss: 0.3926 - acc: 0.8778 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 25/500\n",
      "900/900 [==============================] - 0s 195us/sample - loss: 0.3900 - acc: 0.8789 - val_loss: 0.6861 - val_acc: 0.5600\n",
      "Epoch 26/500\n",
      "900/900 [==============================] - 0s 174us/sample - loss: 0.3876 - acc: 0.8811 - val_loss: 0.6839 - val_acc: 0.5600\n",
      "Epoch 27/500\n",
      "900/900 [==============================] - 0s 219us/sample - loss: 0.3854 - acc: 0.8811 - val_loss: 0.6817 - val_acc: 0.5700\n",
      "Epoch 28/500\n",
      "900/900 [==============================] - 0s 204us/sample - loss: 0.3833 - acc: 0.8811 - val_loss: 0.6778 - val_acc: 0.5700\n",
      "Epoch 29/500\n",
      "900/900 [==============================] - 0s 197us/sample - loss: 0.3812 - acc: 0.8811 - val_loss: 0.6755 - val_acc: 0.5700\n",
      "Epoch 30/500\n",
      "900/900 [==============================] - 0s 191us/sample - loss: 0.3790 - acc: 0.8822 - val_loss: 0.6723 - val_acc: 0.5700\n",
      "Epoch 31/500\n",
      "900/900 [==============================] - 0s 189us/sample - loss: 0.3770 - acc: 0.8822 - val_loss: 0.6694 - val_acc: 0.5700\n",
      "Epoch 32/500\n",
      "900/900 [==============================] - 0s 163us/sample - loss: 0.3750 - acc: 0.8833 - val_loss: 0.6668 - val_acc: 0.5800\n",
      "Epoch 33/500\n",
      "900/900 [==============================] - 0s 189us/sample - loss: 0.3731 - acc: 0.8844 - val_loss: 0.6638 - val_acc: 0.5800\n",
      "Epoch 34/500\n",
      "900/900 [==============================] - 0s 190us/sample - loss: 0.3713 - acc: 0.8844 - val_loss: 0.6606 - val_acc: 0.5800\n",
      "Epoch 35/500\n",
      "900/900 [==============================] - 0s 139us/sample - loss: 0.3695 - acc: 0.8844 - val_loss: 0.6580 - val_acc: 0.5800\n",
      "Epoch 36/500\n",
      "900/900 [==============================] - 0s 240us/sample - loss: 0.3678 - acc: 0.8844 - val_loss: 0.6539 - val_acc: 0.5800\n",
      "Epoch 37/500\n",
      "900/900 [==============================] - 0s 197us/sample - loss: 0.3659 - acc: 0.8844 - val_loss: 0.6514 - val_acc: 0.5800\n",
      "Epoch 38/500\n",
      "900/900 [==============================] - 0s 98us/sample - loss: 0.3643 - acc: 0.8844 - val_loss: 0.6484 - val_acc: 0.5800\n",
      "Epoch 39/500\n",
      "900/900 [==============================] - 0s 169us/sample - loss: 0.3627 - acc: 0.8844 - val_loss: 0.6458 - val_acc: 0.5800\n",
      "Epoch 40/500\n",
      "900/900 [==============================] - 0s 222us/sample - loss: 0.3612 - acc: 0.8844 - val_loss: 0.6432 - val_acc: 0.5800\n",
      "Epoch 41/500\n",
      "900/900 [==============================] - 0s 219us/sample - loss: 0.3597 - acc: 0.8844 - val_loss: 0.6405 - val_acc: 0.5800\n",
      "Epoch 42/500\n",
      "900/900 [==============================] - 0s 198us/sample - loss: 0.3582 - acc: 0.8844 - val_loss: 0.6379 - val_acc: 0.5800\n",
      "Epoch 43/500\n",
      "900/900 [==============================] - 0s 198us/sample - loss: 0.3567 - acc: 0.8844 - val_loss: 0.6353 - val_acc: 0.5800\n",
      "Epoch 44/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.3553 - acc: 0.8844 - val_loss: 0.6320 - val_acc: 0.5800\n",
      "Epoch 45/500\n",
      "900/900 [==============================] - 0s 216us/sample - loss: 0.3538 - acc: 0.8844 - val_loss: 0.6292 - val_acc: 0.5800\n",
      "Epoch 46/500\n",
      "900/900 [==============================] - 0s 151us/sample - loss: 0.3524 - acc: 0.8844 - val_loss: 0.6259 - val_acc: 0.5900\n",
      "Epoch 47/500\n",
      "900/900 [==============================] - 0s 156us/sample - loss: 0.3510 - acc: 0.8878 - val_loss: 0.6229 - val_acc: 0.5900\n",
      "Epoch 48/500\n",
      "900/900 [==============================] - 0s 228us/sample - loss: 0.3496 - acc: 0.8878 - val_loss: 0.6200 - val_acc: 0.5900\n",
      "Epoch 49/500\n",
      "900/900 [==============================] - 0s 93us/sample - loss: 0.3482 - acc: 0.8878 - val_loss: 0.6169 - val_acc: 0.5900\n",
      "Epoch 50/500\n",
      "900/900 [==============================] - 0s 94us/sample - loss: 0.3469 - acc: 0.8878 - val_loss: 0.6135 - val_acc: 0.5900\n",
      "Epoch 51/500\n",
      "900/900 [==============================] - 0s 101us/sample - loss: 0.3455 - acc: 0.8889 - val_loss: 0.6089 - val_acc: 0.5900\n",
      "Epoch 52/500\n",
      "900/900 [==============================] - 0s 86us/sample - loss: 0.3440 - acc: 0.8911 - val_loss: 0.6057 - val_acc: 0.5900\n",
      "Epoch 53/500\n",
      "900/900 [==============================] - 0s 85us/sample - loss: 0.3426 - acc: 0.8911 - val_loss: 0.6023 - val_acc: 0.5900\n",
      "Epoch 54/500\n",
      "900/900 [==============================] - 0s 83us/sample - loss: 0.3413 - acc: 0.8922 - val_loss: 0.5998 - val_acc: 0.6000\n",
      "Epoch 55/500\n",
      "900/900 [==============================] - 0s 81us/sample - loss: 0.3400 - acc: 0.8944 - val_loss: 0.5965 - val_acc: 0.6100\n",
      "Epoch 56/500\n",
      "900/900 [==============================] - 0s 85us/sample - loss: 0.3386 - acc: 0.8967 - val_loss: 0.5930 - val_acc: 0.6100\n",
      "Epoch 57/500\n",
      "900/900 [==============================] - 0s 91us/sample - loss: 0.3373 - acc: 0.9000 - val_loss: 0.5897 - val_acc: 0.6100\n",
      "Epoch 58/500\n",
      "900/900 [==============================] - 0s 152us/sample - loss: 0.3360 - acc: 0.9011 - val_loss: 0.5865 - val_acc: 0.6100\n",
      "Epoch 59/500\n",
      "900/900 [==============================] - 0s 99us/sample - loss: 0.3347 - acc: 0.9011 - val_loss: 0.5831 - val_acc: 0.6300\n",
      "Epoch 60/500\n",
      "900/900 [==============================] - 0s 89us/sample - loss: 0.3334 - acc: 0.9000 - val_loss: 0.5796 - val_acc: 0.6200\n",
      "Epoch 61/500\n",
      "900/900 [==============================] - 0s 82us/sample - loss: 0.3321 - acc: 0.9022 - val_loss: 0.5762 - val_acc: 0.6200\n",
      "Epoch 62/500\n",
      "900/900 [==============================] - 0s 82us/sample - loss: 0.3308 - acc: 0.9056 - val_loss: 0.5722 - val_acc: 0.6200\n",
      "Epoch 63/500\n",
      "900/900 [==============================] - 0s 211us/sample - loss: 0.3295 - acc: 0.9089 - val_loss: 0.5690 - val_acc: 0.6200\n",
      "Epoch 64/500\n",
      "900/900 [==============================] - 0s 207us/sample - loss: 0.3282 - acc: 0.9122 - val_loss: 0.5648 - val_acc: 0.6300\n",
      "Epoch 65/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.3269 - acc: 0.9144 - val_loss: 0.5617 - val_acc: 0.6400\n",
      "Epoch 66/500\n",
      "900/900 [==============================] - 0s 147us/sample - loss: 0.3257 - acc: 0.9189 - val_loss: 0.5587 - val_acc: 0.6500\n",
      "Epoch 67/500\n",
      "900/900 [==============================] - 0s 148us/sample - loss: 0.3246 - acc: 0.9200 - val_loss: 0.5558 - val_acc: 0.6500\n",
      "Epoch 68/500\n",
      "900/900 [==============================] - 0s 144us/sample - loss: 0.3234 - acc: 0.9222 - val_loss: 0.5529 - val_acc: 0.6500\n",
      "Epoch 69/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.3222 - acc: 0.9256 - val_loss: 0.5492 - val_acc: 0.6800\n",
      "Epoch 70/500\n",
      "900/900 [==============================] - 0s 98us/sample - loss: 0.3210 - acc: 0.9256 - val_loss: 0.5473 - val_acc: 0.6900\n",
      "Epoch 71/500\n",
      "900/900 [==============================] - 0s 97us/sample - loss: 0.3200 - acc: 0.9267 - val_loss: 0.5446 - val_acc: 0.7000\n",
      "Epoch 72/500\n",
      "900/900 [==============================] - 0s 113us/sample - loss: 0.3189 - acc: 0.9233 - val_loss: 0.5420 - val_acc: 0.7000\n",
      "Epoch 73/500\n",
      "900/900 [==============================] - 0s 148us/sample - loss: 0.3178 - acc: 0.9244 - val_loss: 0.5398 - val_acc: 0.7300\n",
      "Epoch 74/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.3167 - acc: 0.9233 - val_loss: 0.5370 - val_acc: 0.7300\n",
      "Epoch 75/500\n",
      "900/900 [==============================] - 0s 162us/sample - loss: 0.3156 - acc: 0.9244 - val_loss: 0.5336 - val_acc: 0.7300\n",
      "Epoch 76/500\n",
      "900/900 [==============================] - 0s 151us/sample - loss: 0.3145 - acc: 0.9256 - val_loss: 0.5307 - val_acc: 0.7400\n",
      "Epoch 77/500\n",
      "900/900 [==============================] - 0s 155us/sample - loss: 0.3134 - acc: 0.9267 - val_loss: 0.5285 - val_acc: 0.7400\n",
      "Epoch 78/500\n",
      "900/900 [==============================] - 0s 151us/sample - loss: 0.3124 - acc: 0.9289 - val_loss: 0.5257 - val_acc: 0.7400\n",
      "Epoch 79/500\n",
      "900/900 [==============================] - 0s 169us/sample - loss: 0.3113 - acc: 0.9278 - val_loss: 0.5234 - val_acc: 0.7600\n",
      "Epoch 80/500\n",
      "900/900 [==============================] - 0s 152us/sample - loss: 0.3102 - acc: 0.9278 - val_loss: 0.5211 - val_acc: 0.7600\n",
      "Epoch 81/500\n",
      "900/900 [==============================] - 0s 160us/sample - loss: 0.3092 - acc: 0.9289 - val_loss: 0.5185 - val_acc: 0.7600\n",
      "Epoch 82/500\n",
      "900/900 [==============================] - 0s 154us/sample - loss: 0.3081 - acc: 0.9333 - val_loss: 0.5162 - val_acc: 0.7700\n",
      "Epoch 83/500\n",
      "900/900 [==============================] - 0s 149us/sample - loss: 0.3071 - acc: 0.9344 - val_loss: 0.5139 - val_acc: 0.7700\n",
      "Epoch 84/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.3061 - acc: 0.9344 - val_loss: 0.5116 - val_acc: 0.7700\n",
      "Epoch 85/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.3051 - acc: 0.9344 - val_loss: 0.5093 - val_acc: 0.7700\n",
      "Epoch 86/500\n",
      "900/900 [==============================] - 0s 149us/sample - loss: 0.3041 - acc: 0.9356 - val_loss: 0.5061 - val_acc: 0.7800\n",
      "Epoch 87/500\n",
      "900/900 [==============================] - 0s 130us/sample - loss: 0.3030 - acc: 0.9378 - val_loss: 0.5043 - val_acc: 0.7800\n",
      "Epoch 88/500\n",
      "900/900 [==============================] - 0s 143us/sample - loss: 0.3021 - acc: 0.9378 - val_loss: 0.5021 - val_acc: 0.7800\n",
      "Epoch 89/500\n",
      "900/900 [==============================] - 0s 170us/sample - loss: 0.3011 - acc: 0.9389 - val_loss: 0.5000 - val_acc: 0.7800\n",
      "Epoch 90/500\n",
      "900/900 [==============================] - 0s 246us/sample - loss: 0.3001 - acc: 0.9378 - val_loss: 0.4975 - val_acc: 0.7800\n",
      "Epoch 91/500\n",
      "900/900 [==============================] - 0s 342us/sample - loss: 0.2991 - acc: 0.9378 - val_loss: 0.4948 - val_acc: 0.7800\n",
      "Epoch 92/500\n",
      "900/900 [==============================] - 0s 255us/sample - loss: 0.2981 - acc: 0.9389 - val_loss: 0.4929 - val_acc: 0.7800\n",
      "Epoch 93/500\n",
      "900/900 [==============================] - 0s 167us/sample - loss: 0.2971 - acc: 0.9389 - val_loss: 0.4911 - val_acc: 0.7800\n",
      "Epoch 94/500\n",
      "900/900 [==============================] - 0s 185us/sample - loss: 0.2962 - acc: 0.9389 - val_loss: 0.4879 - val_acc: 0.7800\n",
      "Epoch 95/500\n",
      "900/900 [==============================] - 0s 153us/sample - loss: 0.2951 - acc: 0.9400 - val_loss: 0.4854 - val_acc: 0.7900\n",
      "Epoch 96/500\n",
      "900/900 [==============================] - 0s 165us/sample - loss: 0.2942 - acc: 0.9400 - val_loss: 0.4826 - val_acc: 0.8100\n",
      "Epoch 97/500\n",
      "900/900 [==============================] - 0s 130us/sample - loss: 0.2932 - acc: 0.9411 - val_loss: 0.4812 - val_acc: 0.8100\n",
      "Epoch 98/500\n",
      "900/900 [==============================] - 0s 160us/sample - loss: 0.2922 - acc: 0.9411 - val_loss: 0.4793 - val_acc: 0.8100\n",
      "Epoch 99/500\n",
      "900/900 [==============================] - 0s 147us/sample - loss: 0.2913 - acc: 0.9411 - val_loss: 0.4772 - val_acc: 0.8100\n",
      "Epoch 100/500\n",
      "900/900 [==============================] - 0s 138us/sample - loss: 0.2904 - acc: 0.9444 - val_loss: 0.4752 - val_acc: 0.8100\n",
      "Epoch 101/500\n",
      "900/900 [==============================] - 0s 160us/sample - loss: 0.2895 - acc: 0.9444 - val_loss: 0.4736 - val_acc: 0.8200\n",
      "Epoch 102/500\n",
      "900/900 [==============================] - 0s 152us/sample - loss: 0.2885 - acc: 0.9456 - val_loss: 0.4719 - val_acc: 0.8200\n",
      "Epoch 103/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.2876 - acc: 0.9444 - val_loss: 0.4700 - val_acc: 0.8400\n",
      "Epoch 104/500\n",
      "900/900 [==============================] - 0s 156us/sample - loss: 0.2866 - acc: 0.9456 - val_loss: 0.4671 - val_acc: 0.8500\n",
      "Epoch 105/500\n",
      "900/900 [==============================] - 0s 167us/sample - loss: 0.2856 - acc: 0.9456 - val_loss: 0.4654 - val_acc: 0.8500\n",
      "Epoch 106/500\n",
      "900/900 [==============================] - 0s 141us/sample - loss: 0.2847 - acc: 0.9456 - val_loss: 0.4634 - val_acc: 0.8500\n",
      "Epoch 107/500\n",
      "900/900 [==============================] - 0s 155us/sample - loss: 0.2838 - acc: 0.9478 - val_loss: 0.4617 - val_acc: 0.8600\n",
      "Epoch 108/500\n",
      "900/900 [==============================] - 0s 157us/sample - loss: 0.2829 - acc: 0.9478 - val_loss: 0.4603 - val_acc: 0.8600\n",
      "Epoch 109/500\n",
      "900/900 [==============================] - 0s 157us/sample - loss: 0.2820 - acc: 0.9489 - val_loss: 0.4577 - val_acc: 0.8600\n",
      "Epoch 110/500\n",
      "900/900 [==============================] - 0s 157us/sample - loss: 0.2810 - acc: 0.9489 - val_loss: 0.4557 - val_acc: 0.8600\n",
      "Epoch 111/500\n",
      "900/900 [==============================] - 0s 155us/sample - loss: 0.2801 - acc: 0.9489 - val_loss: 0.4538 - val_acc: 0.8600\n",
      "Epoch 112/500\n",
      "900/900 [==============================] - 0s 141us/sample - loss: 0.2792 - acc: 0.9511 - val_loss: 0.4500 - val_acc: 0.8800\n",
      "Epoch 113/500\n",
      "900/900 [==============================] - 0s 140us/sample - loss: 0.2783 - acc: 0.9500 - val_loss: 0.4481 - val_acc: 0.8800\n",
      "Epoch 114/500\n",
      "900/900 [==============================] - 0s 155us/sample - loss: 0.2774 - acc: 0.9478 - val_loss: 0.4465 - val_acc: 0.8800\n",
      "Epoch 115/500\n",
      "900/900 [==============================] - 0s 166us/sample - loss: 0.2765 - acc: 0.9489 - val_loss: 0.4453 - val_acc: 0.8800\n",
      "Epoch 116/500\n",
      "900/900 [==============================] - 0s 180us/sample - loss: 0.2756 - acc: 0.9489 - val_loss: 0.4438 - val_acc: 0.8800\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 130us/sample - loss: 0.2747 - acc: 0.9489 - val_loss: 0.4422 - val_acc: 0.8800\n",
      "Epoch 118/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.2739 - acc: 0.9489 - val_loss: 0.4409 - val_acc: 0.8800\n",
      "Epoch 119/500\n",
      "900/900 [==============================] - 0s 146us/sample - loss: 0.2730 - acc: 0.9489 - val_loss: 0.4392 - val_acc: 0.8800\n",
      "Epoch 120/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.2722 - acc: 0.9489 - val_loss: 0.4372 - val_acc: 0.8800\n",
      "Epoch 121/500\n",
      "900/900 [==============================] - 0s 143us/sample - loss: 0.2713 - acc: 0.9489 - val_loss: 0.4356 - val_acc: 0.8800\n",
      "Epoch 122/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.2705 - acc: 0.9500 - val_loss: 0.4333 - val_acc: 0.8800\n",
      "Epoch 123/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.2696 - acc: 0.9511 - val_loss: 0.4329 - val_acc: 0.8800\n",
      "Epoch 124/500\n",
      "900/900 [==============================] - 0s 121us/sample - loss: 0.2688 - acc: 0.9511 - val_loss: 0.4310 - val_acc: 0.8900\n",
      "Epoch 125/500\n",
      "900/900 [==============================] - 0s 133us/sample - loss: 0.2680 - acc: 0.9511 - val_loss: 0.4297 - val_acc: 0.8900\n",
      "Epoch 126/500\n",
      "900/900 [==============================] - 0s 103us/sample - loss: 0.2672 - acc: 0.9511 - val_loss: 0.4290 - val_acc: 0.8900\n",
      "Epoch 127/500\n",
      "900/900 [==============================] - 0s 112us/sample - loss: 0.2663 - acc: 0.9511 - val_loss: 0.4271 - val_acc: 0.8900\n",
      "Epoch 128/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.2655 - acc: 0.9511 - val_loss: 0.4254 - val_acc: 0.8900\n",
      "Epoch 129/500\n",
      "900/900 [==============================] - 0s 139us/sample - loss: 0.2647 - acc: 0.9511 - val_loss: 0.4238 - val_acc: 0.8900\n",
      "Epoch 130/500\n",
      "900/900 [==============================] - 0s 135us/sample - loss: 0.2639 - acc: 0.9522 - val_loss: 0.4223 - val_acc: 0.8900\n",
      "Epoch 131/500\n",
      "900/900 [==============================] - 0s 122us/sample - loss: 0.2631 - acc: 0.9522 - val_loss: 0.4196 - val_acc: 0.8900\n",
      "Epoch 132/500\n",
      "900/900 [==============================] - 0s 127us/sample - loss: 0.2623 - acc: 0.9522 - val_loss: 0.4183 - val_acc: 0.8900\n",
      "Epoch 133/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.2615 - acc: 0.9522 - val_loss: 0.4172 - val_acc: 0.8900\n",
      "Epoch 134/500\n",
      "900/900 [==============================] - 0s 132us/sample - loss: 0.2607 - acc: 0.9522 - val_loss: 0.4161 - val_acc: 0.8900\n",
      "Epoch 135/500\n",
      "900/900 [==============================] - 0s 125us/sample - loss: 0.2599 - acc: 0.9522 - val_loss: 0.4144 - val_acc: 0.8900\n",
      "Epoch 136/500\n",
      "900/900 [==============================] - 0s 117us/sample - loss: 0.2591 - acc: 0.9522 - val_loss: 0.4130 - val_acc: 0.8900\n",
      "Epoch 137/500\n",
      "900/900 [==============================] - 0s 121us/sample - loss: 0.2583 - acc: 0.9522 - val_loss: 0.4099 - val_acc: 0.9000\n",
      "Epoch 138/500\n",
      "900/900 [==============================] - 0s 123us/sample - loss: 0.2575 - acc: 0.9522 - val_loss: 0.4091 - val_acc: 0.9000\n",
      "Epoch 139/500\n",
      "900/900 [==============================] - 0s 152us/sample - loss: 0.2568 - acc: 0.9522 - val_loss: 0.4076 - val_acc: 0.9000\n",
      "Epoch 140/500\n",
      "900/900 [==============================] - 0s 110us/sample - loss: 0.2560 - acc: 0.9533 - val_loss: 0.4064 - val_acc: 0.9000\n",
      "Epoch 141/500\n",
      "900/900 [==============================] - 0s 120us/sample - loss: 0.2552 - acc: 0.9533 - val_loss: 0.4050 - val_acc: 0.9000\n",
      "Epoch 142/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.2545 - acc: 0.9533 - val_loss: 0.4035 - val_acc: 0.9000\n",
      "Epoch 143/500\n",
      "900/900 [==============================] - 0s 107us/sample - loss: 0.2537 - acc: 0.9533 - val_loss: 0.4031 - val_acc: 0.9000\n",
      "Epoch 144/500\n",
      "900/900 [==============================] - 0s 120us/sample - loss: 0.2529 - acc: 0.9533 - val_loss: 0.4028 - val_acc: 0.9000\n",
      "Epoch 145/500\n",
      "900/900 [==============================] - 0s 123us/sample - loss: 0.2522 - acc: 0.9533 - val_loss: 0.4016 - val_acc: 0.9000\n",
      "Epoch 146/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.2514 - acc: 0.9533 - val_loss: 0.4006 - val_acc: 0.9000\n",
      "Epoch 147/500\n",
      "900/900 [==============================] - 0s 150us/sample - loss: 0.2506 - acc: 0.9544 - val_loss: 0.3986 - val_acc: 0.9000\n",
      "Epoch 148/500\n",
      "900/900 [==============================] - 0s 142us/sample - loss: 0.2498 - acc: 0.9533 - val_loss: 0.3976 - val_acc: 0.9000\n",
      "Epoch 149/500\n",
      "900/900 [==============================] - 0s 142us/sample - loss: 0.2490 - acc: 0.9544 - val_loss: 0.3963 - val_acc: 0.9000\n",
      "Epoch 150/500\n",
      "900/900 [==============================] - 0s 143us/sample - loss: 0.2482 - acc: 0.9556 - val_loss: 0.3947 - val_acc: 0.9000\n",
      "Epoch 151/500\n",
      "900/900 [==============================] - 0s 167us/sample - loss: 0.2474 - acc: 0.9578 - val_loss: 0.3944 - val_acc: 0.9000\n",
      "Epoch 152/500\n",
      "900/900 [==============================] - 0s 137us/sample - loss: 0.2466 - acc: 0.9589 - val_loss: 0.3941 - val_acc: 0.9000\n",
      "Epoch 153/500\n",
      "900/900 [==============================] - 0s 142us/sample - loss: 0.2458 - acc: 0.9589 - val_loss: 0.3919 - val_acc: 0.9000\n",
      "Epoch 154/500\n",
      "900/900 [==============================] - 0s 132us/sample - loss: 0.2450 - acc: 0.9589 - val_loss: 0.3908 - val_acc: 0.9000\n",
      "Epoch 155/500\n",
      "900/900 [==============================] - 0s 157us/sample - loss: 0.2442 - acc: 0.9589 - val_loss: 0.3896 - val_acc: 0.9000\n",
      "Epoch 156/500\n",
      "900/900 [==============================] - 0s 165us/sample - loss: 0.2435 - acc: 0.9589 - val_loss: 0.3884 - val_acc: 0.9000\n",
      "Epoch 157/500\n",
      "900/900 [==============================] - 0s 184us/sample - loss: 0.2427 - acc: 0.9589 - val_loss: 0.3873 - val_acc: 0.9000\n",
      "Epoch 158/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.2419 - acc: 0.9589 - val_loss: 0.3852 - val_acc: 0.9000\n",
      "Epoch 159/500\n",
      "900/900 [==============================] - 0s 123us/sample - loss: 0.2411 - acc: 0.9600 - val_loss: 0.3848 - val_acc: 0.9000\n",
      "Epoch 160/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.2404 - acc: 0.9600 - val_loss: 0.3836 - val_acc: 0.9100\n",
      "Epoch 161/500\n",
      "900/900 [==============================] - 0s 146us/sample - loss: 0.2396 - acc: 0.9600 - val_loss: 0.3824 - val_acc: 0.9100\n",
      "Epoch 162/500\n",
      "900/900 [==============================] - 0s 117us/sample - loss: 0.2389 - acc: 0.9600 - val_loss: 0.3818 - val_acc: 0.9100\n",
      "Epoch 163/500\n",
      "900/900 [==============================] - 0s 117us/sample - loss: 0.2381 - acc: 0.9600 - val_loss: 0.3815 - val_acc: 0.9100\n",
      "Epoch 164/500\n",
      "900/900 [==============================] - 0s 114us/sample - loss: 0.2373 - acc: 0.9600 - val_loss: 0.3795 - val_acc: 0.9100\n",
      "Epoch 165/500\n",
      "900/900 [==============================] - 0s 147us/sample - loss: 0.2365 - acc: 0.9600 - val_loss: 0.3790 - val_acc: 0.9100\n",
      "Epoch 166/500\n",
      "900/900 [==============================] - 0s 116us/sample - loss: 0.2357 - acc: 0.9600 - val_loss: 0.3786 - val_acc: 0.9100\n",
      "Epoch 167/500\n",
      "900/900 [==============================] - 0s 147us/sample - loss: 0.2350 - acc: 0.9600 - val_loss: 0.3771 - val_acc: 0.9100\n",
      "Epoch 168/500\n",
      "900/900 [==============================] - 0s 135us/sample - loss: 0.2343 - acc: 0.9600 - val_loss: 0.3760 - val_acc: 0.9100\n",
      "Epoch 169/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.2335 - acc: 0.9600 - val_loss: 0.3748 - val_acc: 0.9200\n",
      "Epoch 170/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.2328 - acc: 0.9600 - val_loss: 0.3736 - val_acc: 0.9200\n",
      "Epoch 171/500\n",
      "900/900 [==============================] - 0s 123us/sample - loss: 0.2321 - acc: 0.9600 - val_loss: 0.3725 - val_acc: 0.9200\n",
      "Epoch 172/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.2313 - acc: 0.9600 - val_loss: 0.3697 - val_acc: 0.9200\n",
      "Epoch 173/500\n",
      "900/900 [==============================] - 0s 130us/sample - loss: 0.2305 - acc: 0.9611 - val_loss: 0.3689 - val_acc: 0.9200\n",
      "Epoch 174/500\n",
      "900/900 [==============================] - 0s 115us/sample - loss: 0.2297 - acc: 0.9611 - val_loss: 0.3679 - val_acc: 0.9200\n",
      "Epoch 175/500\n",
      "900/900 [==============================] - 0s 120us/sample - loss: 0.2290 - acc: 0.9611 - val_loss: 0.3667 - val_acc: 0.9200\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 118us/sample - loss: 0.2282 - acc: 0.9667 - val_loss: 0.3652 - val_acc: 0.9200\n",
      "Epoch 177/500\n",
      "900/900 [==============================] - 0s 117us/sample - loss: 0.2275 - acc: 0.9667 - val_loss: 0.3640 - val_acc: 0.9200\n",
      "Epoch 178/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.2267 - acc: 0.9667 - val_loss: 0.3619 - val_acc: 0.9200\n",
      "Epoch 179/500\n",
      "900/900 [==============================] - 0s 112us/sample - loss: 0.2260 - acc: 0.9667 - val_loss: 0.3617 - val_acc: 0.9200\n",
      "Epoch 180/500\n",
      "900/900 [==============================] - 0s 112us/sample - loss: 0.2252 - acc: 0.9667 - val_loss: 0.3597 - val_acc: 0.9200\n",
      "Epoch 181/500\n",
      "900/900 [==============================] - 0s 115us/sample - loss: 0.2245 - acc: 0.9678 - val_loss: 0.3587 - val_acc: 0.9200\n",
      "Epoch 182/500\n",
      "900/900 [==============================] - 0s 118us/sample - loss: 0.2238 - acc: 0.9667 - val_loss: 0.3575 - val_acc: 0.9200\n",
      "Epoch 183/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.2230 - acc: 0.9678 - val_loss: 0.3562 - val_acc: 0.9200\n",
      "Epoch 184/500\n",
      "900/900 [==============================] - 0s 122us/sample - loss: 0.2223 - acc: 0.9678 - val_loss: 0.3550 - val_acc: 0.9200\n",
      "Epoch 185/500\n",
      "900/900 [==============================] - 0s 111us/sample - loss: 0.2216 - acc: 0.9678 - val_loss: 0.3539 - val_acc: 0.9200\n",
      "Epoch 186/500\n",
      "900/900 [==============================] - 0s 127us/sample - loss: 0.2208 - acc: 0.9678 - val_loss: 0.3529 - val_acc: 0.9200\n",
      "Epoch 187/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.2202 - acc: 0.9678 - val_loss: 0.3520 - val_acc: 0.9200\n",
      "Epoch 188/500\n",
      "900/900 [==============================] - 0s 110us/sample - loss: 0.2195 - acc: 0.9678 - val_loss: 0.3512 - val_acc: 0.9200\n",
      "Epoch 189/500\n",
      "900/900 [==============================] - 0s 125us/sample - loss: 0.2188 - acc: 0.9678 - val_loss: 0.3503 - val_acc: 0.9200\n",
      "Epoch 190/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.2181 - acc: 0.9678 - val_loss: 0.3496 - val_acc: 0.9200\n",
      "Epoch 191/500\n",
      "900/900 [==============================] - 0s 113us/sample - loss: 0.2174 - acc: 0.9678 - val_loss: 0.3486 - val_acc: 0.9200\n",
      "Epoch 192/500\n",
      "900/900 [==============================] - 0s 108us/sample - loss: 0.2167 - acc: 0.9678 - val_loss: 0.3474 - val_acc: 0.9200\n",
      "Epoch 193/500\n",
      "900/900 [==============================] - 0s 81us/sample - loss: 0.2161 - acc: 0.9678 - val_loss: 0.3463 - val_acc: 0.9200\n",
      "Epoch 194/500\n",
      "900/900 [==============================] - 0s 81us/sample - loss: 0.2154 - acc: 0.9689 - val_loss: 0.3446 - val_acc: 0.9200\n",
      "Epoch 195/500\n",
      "900/900 [==============================] - 0s 80us/sample - loss: 0.2147 - acc: 0.9689 - val_loss: 0.3411 - val_acc: 0.9200\n",
      "Epoch 196/500\n",
      "900/900 [==============================] - 0s 97us/sample - loss: 0.2140 - acc: 0.9700 - val_loss: 0.3426 - val_acc: 0.9200\n",
      "Epoch 197/500\n",
      "900/900 [==============================] - 0s 114us/sample - loss: 0.2134 - acc: 0.9689 - val_loss: 0.3426 - val_acc: 0.9200\n",
      "Epoch 198/500\n",
      "900/900 [==============================] - 0s 125us/sample - loss: 0.2127 - acc: 0.9689 - val_loss: 0.3416 - val_acc: 0.9200\n",
      "Epoch 199/500\n",
      "900/900 [==============================] - 0s 109us/sample - loss: 0.2120 - acc: 0.9689 - val_loss: 0.3425 - val_acc: 0.9200\n",
      "Epoch 200/500\n",
      "900/900 [==============================] - 0s 114us/sample - loss: 0.2114 - acc: 0.9678 - val_loss: 0.3406 - val_acc: 0.9200\n",
      "Epoch 201/500\n",
      "900/900 [==============================] - 0s 112us/sample - loss: 0.2107 - acc: 0.9678 - val_loss: 0.3397 - val_acc: 0.9200\n",
      "Epoch 202/500\n",
      "900/900 [==============================] - 0s 125us/sample - loss: 0.2101 - acc: 0.9678 - val_loss: 0.3380 - val_acc: 0.9200\n",
      "Epoch 203/500\n",
      "900/900 [==============================] - 0s 127us/sample - loss: 0.2094 - acc: 0.9678 - val_loss: 0.3375 - val_acc: 0.9200\n",
      "Epoch 204/500\n",
      "900/900 [==============================] - 0s 116us/sample - loss: 0.2088 - acc: 0.9678 - val_loss: 0.3368 - val_acc: 0.9200\n",
      "Epoch 205/500\n",
      "900/900 [==============================] - 0s 121us/sample - loss: 0.2081 - acc: 0.9678 - val_loss: 0.3363 - val_acc: 0.9200\n",
      "Epoch 206/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.2075 - acc: 0.9678 - val_loss: 0.3349 - val_acc: 0.9200\n",
      "Epoch 207/500\n",
      "900/900 [==============================] - 0s 113us/sample - loss: 0.2069 - acc: 0.9700 - val_loss: 0.3350 - val_acc: 0.9200\n",
      "Epoch 208/500\n",
      "900/900 [==============================] - 0s 130us/sample - loss: 0.2063 - acc: 0.9700 - val_loss: 0.3342 - val_acc: 0.9200\n",
      "Epoch 209/500\n",
      "900/900 [==============================] - 0s 127us/sample - loss: 0.2057 - acc: 0.9700 - val_loss: 0.3333 - val_acc: 0.9200\n",
      "Epoch 210/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.2051 - acc: 0.9700 - val_loss: 0.3328 - val_acc: 0.9200\n",
      "Epoch 211/500\n",
      "900/900 [==============================] - 0s 116us/sample - loss: 0.2045 - acc: 0.9689 - val_loss: 0.3321 - val_acc: 0.9200\n",
      "Epoch 212/500\n",
      "900/900 [==============================] - 0s 83us/sample - loss: 0.2039 - acc: 0.9700 - val_loss: 0.3312 - val_acc: 0.9200\n",
      "Epoch 213/500\n",
      "900/900 [==============================] - 0s 80us/sample - loss: 0.2033 - acc: 0.9700 - val_loss: 0.3301 - val_acc: 0.9200\n",
      "Epoch 214/500\n",
      "900/900 [==============================] - 0s 82us/sample - loss: 0.2027 - acc: 0.9700 - val_loss: 0.3296 - val_acc: 0.9200\n",
      "Epoch 215/500\n",
      "900/900 [==============================] - 0s 84us/sample - loss: 0.2021 - acc: 0.9700 - val_loss: 0.3286 - val_acc: 0.9200\n",
      "Epoch 216/500\n",
      "900/900 [==============================] - 0s 121us/sample - loss: 0.2015 - acc: 0.9700 - val_loss: 0.3291 - val_acc: 0.9200\n",
      "Epoch 217/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.2010 - acc: 0.9700 - val_loss: 0.3281 - val_acc: 0.9200\n",
      "Epoch 218/500\n",
      "900/900 [==============================] - 0s 127us/sample - loss: 0.2004 - acc: 0.9722 - val_loss: 0.3272 - val_acc: 0.9200\n",
      "Epoch 219/500\n",
      "900/900 [==============================] - 0s 127us/sample - loss: 0.1998 - acc: 0.9733 - val_loss: 0.3261 - val_acc: 0.9200\n",
      "Epoch 220/500\n",
      "900/900 [==============================] - 0s 127us/sample - loss: 0.1992 - acc: 0.9744 - val_loss: 0.3251 - val_acc: 0.9200\n",
      "Epoch 221/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.1987 - acc: 0.9744 - val_loss: 0.3235 - val_acc: 0.9200\n",
      "Epoch 222/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.1981 - acc: 0.9744 - val_loss: 0.3228 - val_acc: 0.9200\n",
      "Epoch 223/500\n",
      "900/900 [==============================] - 0s 112us/sample - loss: 0.1976 - acc: 0.9744 - val_loss: 0.3222 - val_acc: 0.9200\n",
      "Epoch 224/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1970 - acc: 0.9733 - val_loss: 0.3215 - val_acc: 0.9200\n",
      "Epoch 225/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1964 - acc: 0.9733 - val_loss: 0.3216 - val_acc: 0.9200\n",
      "Epoch 226/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.1959 - acc: 0.9744 - val_loss: 0.3205 - val_acc: 0.9200\n",
      "Epoch 227/500\n",
      "900/900 [==============================] - 0s 130us/sample - loss: 0.1954 - acc: 0.9744 - val_loss: 0.3209 - val_acc: 0.9200\n",
      "Epoch 228/500\n",
      "900/900 [==============================] - 0s 115us/sample - loss: 0.1948 - acc: 0.9744 - val_loss: 0.3196 - val_acc: 0.9200\n",
      "Epoch 229/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.1943 - acc: 0.9733 - val_loss: 0.3186 - val_acc: 0.9200\n",
      "Epoch 230/500\n",
      "900/900 [==============================] - 0s 101us/sample - loss: 0.1937 - acc: 0.9744 - val_loss: 0.3173 - val_acc: 0.9200\n",
      "Epoch 231/500\n",
      "900/900 [==============================] - 0s 91us/sample - loss: 0.1931 - acc: 0.9733 - val_loss: 0.3166 - val_acc: 0.9200\n",
      "Epoch 232/500\n",
      "900/900 [==============================] - 0s 83us/sample - loss: 0.1926 - acc: 0.9733 - val_loss: 0.3159 - val_acc: 0.9200\n",
      "Epoch 233/500\n",
      "900/900 [==============================] - 0s 81us/sample - loss: 0.1921 - acc: 0.9733 - val_loss: 0.3154 - val_acc: 0.9300\n",
      "Epoch 234/500\n",
      "900/900 [==============================] - 0s 111us/sample - loss: 0.1915 - acc: 0.9733 - val_loss: 0.3146 - val_acc: 0.9300\n",
      "Epoch 235/500\n",
      "900/900 [==============================] - 0s 118us/sample - loss: 0.1910 - acc: 0.9744 - val_loss: 0.3146 - val_acc: 0.9300\n",
      "Epoch 236/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1905 - acc: 0.9744 - val_loss: 0.3156 - val_acc: 0.9200\n",
      "Epoch 237/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1900 - acc: 0.9744 - val_loss: 0.3145 - val_acc: 0.9200\n",
      "Epoch 238/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1895 - acc: 0.9744 - val_loss: 0.3138 - val_acc: 0.9200\n",
      "Epoch 239/500\n",
      "900/900 [==============================] - 0s 113us/sample - loss: 0.1890 - acc: 0.9744 - val_loss: 0.3124 - val_acc: 0.9300\n",
      "Epoch 240/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.1885 - acc: 0.9744 - val_loss: 0.3121 - val_acc: 0.9200\n",
      "Epoch 241/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.1879 - acc: 0.9744 - val_loss: 0.3095 - val_acc: 0.9300\n",
      "Epoch 242/500\n",
      "900/900 [==============================] - 0s 130us/sample - loss: 0.1874 - acc: 0.9744 - val_loss: 0.3083 - val_acc: 0.9300\n",
      "Epoch 243/500\n",
      "900/900 [==============================] - 0s 115us/sample - loss: 0.1869 - acc: 0.9744 - val_loss: 0.3081 - val_acc: 0.9300\n",
      "Epoch 244/500\n",
      "900/900 [==============================] - 0s 134us/sample - loss: 0.1864 - acc: 0.9744 - val_loss: 0.3085 - val_acc: 0.9300\n",
      "Epoch 245/500\n",
      "900/900 [==============================] - 0s 122us/sample - loss: 0.1859 - acc: 0.9744 - val_loss: 0.3084 - val_acc: 0.9300\n",
      "Epoch 246/500\n",
      "900/900 [==============================] - 0s 134us/sample - loss: 0.1854 - acc: 0.9744 - val_loss: 0.3046 - val_acc: 0.9300\n",
      "Epoch 247/500\n",
      "900/900 [==============================] - 0s 118us/sample - loss: 0.1849 - acc: 0.9722 - val_loss: 0.3047 - val_acc: 0.9300\n",
      "Epoch 248/500\n",
      "900/900 [==============================] - 0s 115us/sample - loss: 0.1844 - acc: 0.9722 - val_loss: 0.3045 - val_acc: 0.9300\n",
      "Epoch 249/500\n",
      "900/900 [==============================] - 0s 83us/sample - loss: 0.1839 - acc: 0.9722 - val_loss: 0.3015 - val_acc: 0.9300\n",
      "Epoch 250/500\n",
      "900/900 [==============================] - 0s 84us/sample - loss: 0.1834 - acc: 0.9722 - val_loss: 0.3017 - val_acc: 0.9300\n",
      "Epoch 251/500\n",
      "900/900 [==============================] - 0s 80us/sample - loss: 0.1830 - acc: 0.9722 - val_loss: 0.3018 - val_acc: 0.9300\n",
      "Epoch 252/500\n",
      "900/900 [==============================] - 0s 91us/sample - loss: 0.1825 - acc: 0.9722 - val_loss: 0.3011 - val_acc: 0.9300\n",
      "Epoch 253/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.1820 - acc: 0.9722 - val_loss: 0.2999 - val_acc: 0.9300\n",
      "Epoch 254/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1816 - acc: 0.9722 - val_loss: 0.3003 - val_acc: 0.9300\n",
      "Epoch 255/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.1811 - acc: 0.9722 - val_loss: 0.3001 - val_acc: 0.9300\n",
      "Epoch 256/500\n",
      "900/900 [==============================] - 0s 142us/sample - loss: 0.1806 - acc: 0.9722 - val_loss: 0.3000 - val_acc: 0.9300\n",
      "Epoch 257/500\n",
      "900/900 [==============================] - 0s 133us/sample - loss: 0.1801 - acc: 0.9733 - val_loss: 0.3002 - val_acc: 0.9300\n",
      "Epoch 258/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.1796 - acc: 0.9722 - val_loss: 0.3001 - val_acc: 0.9300\n",
      "Epoch 259/500\n",
      "900/900 [==============================] - 0s 138us/sample - loss: 0.1792 - acc: 0.9722 - val_loss: 0.3000 - val_acc: 0.9300\n",
      "Epoch 260/500\n",
      "900/900 [==============================] - 0s 151us/sample - loss: 0.1787 - acc: 0.9733 - val_loss: 0.2998 - val_acc: 0.9300\n",
      "Epoch 261/500\n",
      "900/900 [==============================] - 0s 135us/sample - loss: 0.1783 - acc: 0.9744 - val_loss: 0.3003 - val_acc: 0.9300\n",
      "Epoch 262/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.1778 - acc: 0.9733 - val_loss: 0.3000 - val_acc: 0.9300\n",
      "Epoch 263/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.1774 - acc: 0.9722 - val_loss: 0.3009 - val_acc: 0.9200\n",
      "Epoch 264/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.1770 - acc: 0.9744 - val_loss: 0.3005 - val_acc: 0.9200\n",
      "Epoch 265/500\n",
      "900/900 [==============================] - 0s 113us/sample - loss: 0.1765 - acc: 0.9744 - val_loss: 0.3000 - val_acc: 0.9200\n",
      "Epoch 266/500\n",
      "900/900 [==============================] - 0s 119us/sample - loss: 0.1761 - acc: 0.9744 - val_loss: 0.2995 - val_acc: 0.9200\n",
      "Epoch 267/500\n",
      "900/900 [==============================] - 0s 123us/sample - loss: 0.1756 - acc: 0.9744 - val_loss: 0.2990 - val_acc: 0.9200\n",
      "Epoch 268/500\n",
      "900/900 [==============================] - 0s 139us/sample - loss: 0.1752 - acc: 0.9744 - val_loss: 0.2988 - val_acc: 0.9200\n",
      "Epoch 269/500\n",
      "900/900 [==============================] - 0s 142us/sample - loss: 0.1748 - acc: 0.9744 - val_loss: 0.2983 - val_acc: 0.9200\n",
      "Epoch 270/500\n",
      "900/900 [==============================] - 0s 130us/sample - loss: 0.1743 - acc: 0.9744 - val_loss: 0.2981 - val_acc: 0.9200\n",
      "Epoch 271/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.1739 - acc: 0.9744 - val_loss: 0.2979 - val_acc: 0.9200\n",
      "Epoch 272/500\n",
      "900/900 [==============================] - 0s 144us/sample - loss: 0.1735 - acc: 0.9744 - val_loss: 0.2976 - val_acc: 0.9200\n",
      "Epoch 273/500\n",
      "900/900 [==============================] - 0s 141us/sample - loss: 0.1730 - acc: 0.9756 - val_loss: 0.2967 - val_acc: 0.9200\n",
      "Epoch 274/500\n",
      "900/900 [==============================] - 0s 141us/sample - loss: 0.1726 - acc: 0.9756 - val_loss: 0.2962 - val_acc: 0.9200\n",
      "Epoch 275/500\n",
      "900/900 [==============================] - 0s 127us/sample - loss: 0.1722 - acc: 0.9756 - val_loss: 0.2963 - val_acc: 0.9200\n",
      "Epoch 276/500\n",
      "900/900 [==============================] - 0s 141us/sample - loss: 0.1718 - acc: 0.9744 - val_loss: 0.2960 - val_acc: 0.9200\n",
      "Epoch 277/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.1714 - acc: 0.9744 - val_loss: 0.2949 - val_acc: 0.9200\n",
      "Epoch 278/500\n",
      "900/900 [==============================] - 0s 172us/sample - loss: 0.1709 - acc: 0.9744 - val_loss: 0.2946 - val_acc: 0.9200\n",
      "Epoch 279/500\n",
      "900/900 [==============================] - 0s 285us/sample - loss: 0.1705 - acc: 0.9756 - val_loss: 0.2946 - val_acc: 0.9200\n",
      "Epoch 280/500\n",
      "900/900 [==============================] - 0s 189us/sample - loss: 0.1701 - acc: 0.9756 - val_loss: 0.2945 - val_acc: 0.9200\n",
      "Epoch 281/500\n",
      "900/900 [==============================] - 0s 210us/sample - loss: 0.1697 - acc: 0.9756 - val_loss: 0.2944 - val_acc: 0.9200\n",
      "Epoch 282/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.1693 - acc: 0.9756 - val_loss: 0.2943 - val_acc: 0.9200\n",
      "Epoch 283/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.1689 - acc: 0.9756 - val_loss: 0.2941 - val_acc: 0.9200\n",
      "Epoch 284/500\n",
      "900/900 [==============================] - 0s 123us/sample - loss: 0.1685 - acc: 0.9756 - val_loss: 0.2929 - val_acc: 0.9200\n",
      "Epoch 285/500\n",
      "900/900 [==============================] - 0s 153us/sample - loss: 0.1681 - acc: 0.9756 - val_loss: 0.2932 - val_acc: 0.9200\n",
      "Epoch 286/500\n",
      "900/900 [==============================] - 0s 148us/sample - loss: 0.1677 - acc: 0.9756 - val_loss: 0.2923 - val_acc: 0.9200\n",
      "Epoch 287/500\n",
      "900/900 [==============================] - 0s 138us/sample - loss: 0.1673 - acc: 0.9756 - val_loss: 0.2919 - val_acc: 0.9300\n",
      "Epoch 288/500\n",
      "900/900 [==============================] - 0s 150us/sample - loss: 0.1669 - acc: 0.9756 - val_loss: 0.2916 - val_acc: 0.9300\n",
      "Epoch 289/500\n",
      "900/900 [==============================] - 0s 142us/sample - loss: 0.1665 - acc: 0.9756 - val_loss: 0.2914 - val_acc: 0.9300\n",
      "Epoch 290/500\n",
      "900/900 [==============================] - 0s 156us/sample - loss: 0.1661 - acc: 0.9756 - val_loss: 0.2910 - val_acc: 0.9300\n",
      "Epoch 291/500\n",
      "900/900 [==============================] - 0s 147us/sample - loss: 0.1657 - acc: 0.9756 - val_loss: 0.2901 - val_acc: 0.9300\n",
      "Epoch 292/500\n",
      "900/900 [==============================] - 0s 161us/sample - loss: 0.1653 - acc: 0.9756 - val_loss: 0.2898 - val_acc: 0.9300\n",
      "Epoch 293/500\n",
      "900/900 [==============================] - 0s 130us/sample - loss: 0.1650 - acc: 0.9756 - val_loss: 0.2894 - val_acc: 0.9300\n",
      "Epoch 294/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 164us/sample - loss: 0.1646 - acc: 0.9756 - val_loss: 0.2894 - val_acc: 0.9300\n",
      "Epoch 295/500\n",
      "900/900 [==============================] - 0s 102us/sample - loss: 0.1642 - acc: 0.9756 - val_loss: 0.2901 - val_acc: 0.9300\n",
      "Epoch 296/500\n",
      "900/900 [==============================] - 0s 106us/sample - loss: 0.1638 - acc: 0.9756 - val_loss: 0.2895 - val_acc: 0.9300\n",
      "Epoch 297/500\n",
      "900/900 [==============================] - 0s 102us/sample - loss: 0.1634 - acc: 0.9756 - val_loss: 0.2898 - val_acc: 0.9300\n",
      "Epoch 298/500\n",
      "900/900 [==============================] - 0s 120us/sample - loss: 0.1630 - acc: 0.9756 - val_loss: 0.2895 - val_acc: 0.9300\n",
      "Epoch 299/500\n",
      "900/900 [==============================] - 0s 157us/sample - loss: 0.1626 - acc: 0.9756 - val_loss: 0.2889 - val_acc: 0.9300\n",
      "Epoch 300/500\n",
      "900/900 [==============================] - 0s 117us/sample - loss: 0.1623 - acc: 0.9756 - val_loss: 0.2886 - val_acc: 0.9300\n",
      "Epoch 301/500\n",
      "900/900 [==============================] - 0s 110us/sample - loss: 0.1619 - acc: 0.9756 - val_loss: 0.2882 - val_acc: 0.9300\n",
      "Epoch 302/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.1615 - acc: 0.9744 - val_loss: 0.2876 - val_acc: 0.9300\n",
      "Epoch 303/500\n",
      "900/900 [==============================] - 0s 121us/sample - loss: 0.1612 - acc: 0.9744 - val_loss: 0.2878 - val_acc: 0.9300\n",
      "Epoch 304/500\n",
      "900/900 [==============================] - 0s 118us/sample - loss: 0.1608 - acc: 0.9744 - val_loss: 0.2875 - val_acc: 0.9300\n",
      "Epoch 305/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.1604 - acc: 0.9744 - val_loss: 0.2875 - val_acc: 0.9300\n",
      "Epoch 306/500\n",
      "900/900 [==============================] - 0s 120us/sample - loss: 0.1600 - acc: 0.9744 - val_loss: 0.2871 - val_acc: 0.9300\n",
      "Epoch 307/500\n",
      "900/900 [==============================] - 0s 118us/sample - loss: 0.1597 - acc: 0.9744 - val_loss: 0.2867 - val_acc: 0.9300\n",
      "Epoch 308/500\n",
      "900/900 [==============================] - 0s 121us/sample - loss: 0.1593 - acc: 0.9744 - val_loss: 0.2865 - val_acc: 0.9300\n",
      "Epoch 309/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.1589 - acc: 0.9744 - val_loss: 0.2865 - val_acc: 0.9300\n",
      "Epoch 310/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.1585 - acc: 0.9744 - val_loss: 0.2835 - val_acc: 0.9300\n",
      "Epoch 311/500\n",
      "900/900 [==============================] - 0s 123us/sample - loss: 0.1582 - acc: 0.9756 - val_loss: 0.2830 - val_acc: 0.9300\n",
      "Epoch 312/500\n",
      "900/900 [==============================] - 0s 146us/sample - loss: 0.1578 - acc: 0.9756 - val_loss: 0.2831 - val_acc: 0.9300\n",
      "Epoch 313/500\n",
      "900/900 [==============================] - 0s 125us/sample - loss: 0.1574 - acc: 0.9756 - val_loss: 0.2824 - val_acc: 0.9300\n",
      "Epoch 314/500\n",
      "900/900 [==============================] - 0s 119us/sample - loss: 0.1570 - acc: 0.9756 - val_loss: 0.2823 - val_acc: 0.9300\n",
      "Epoch 315/500\n",
      "900/900 [==============================] - 0s 108us/sample - loss: 0.1567 - acc: 0.9756 - val_loss: 0.2830 - val_acc: 0.9300\n",
      "Epoch 316/500\n",
      "900/900 [==============================] - 0s 117us/sample - loss: 0.1563 - acc: 0.9756 - val_loss: 0.2826 - val_acc: 0.9300\n",
      "Epoch 317/500\n",
      "900/900 [==============================] - 0s 118us/sample - loss: 0.1559 - acc: 0.9767 - val_loss: 0.2832 - val_acc: 0.9300\n",
      "Epoch 318/500\n",
      "900/900 [==============================] - 0s 114us/sample - loss: 0.1556 - acc: 0.9767 - val_loss: 0.2831 - val_acc: 0.9300\n",
      "Epoch 319/500\n",
      "900/900 [==============================] - 0s 134us/sample - loss: 0.1552 - acc: 0.9767 - val_loss: 0.2848 - val_acc: 0.9300\n",
      "Epoch 320/500\n",
      "900/900 [==============================] - 0s 118us/sample - loss: 0.1548 - acc: 0.9778 - val_loss: 0.2841 - val_acc: 0.9300\n",
      "Epoch 321/500\n",
      "900/900 [==============================] - 0s 136us/sample - loss: 0.1545 - acc: 0.9778 - val_loss: 0.2834 - val_acc: 0.9300\n",
      "Epoch 322/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1541 - acc: 0.9778 - val_loss: 0.2800 - val_acc: 0.9300\n",
      "Epoch 323/500\n",
      "900/900 [==============================] - 0s 117us/sample - loss: 0.1538 - acc: 0.9789 - val_loss: 0.2799 - val_acc: 0.9300\n",
      "Epoch 324/500\n",
      "900/900 [==============================] - 0s 158us/sample - loss: 0.1534 - acc: 0.9789 - val_loss: 0.2803 - val_acc: 0.9300\n",
      "Epoch 325/500\n",
      "900/900 [==============================] - 0s 173us/sample - loss: 0.1530 - acc: 0.9789 - val_loss: 0.2772 - val_acc: 0.9300\n",
      "Epoch 326/500\n",
      "900/900 [==============================] - 0s 151us/sample - loss: 0.1528 - acc: 0.9778 - val_loss: 0.2775 - val_acc: 0.9300\n",
      "Epoch 327/500\n",
      "900/900 [==============================] - 0s 147us/sample - loss: 0.1524 - acc: 0.9789 - val_loss: 0.2778 - val_acc: 0.9300\n",
      "Epoch 328/500\n",
      "900/900 [==============================] - 0s 141us/sample - loss: 0.1520 - acc: 0.9789 - val_loss: 0.2773 - val_acc: 0.9300\n",
      "Epoch 329/500\n",
      "900/900 [==============================] - 0s 134us/sample - loss: 0.1517 - acc: 0.9789 - val_loss: 0.2782 - val_acc: 0.9300\n",
      "Epoch 330/500\n",
      "900/900 [==============================] - 0s 132us/sample - loss: 0.1513 - acc: 0.9789 - val_loss: 0.2780 - val_acc: 0.9300\n",
      "Epoch 331/500\n",
      "900/900 [==============================] - 0s 123us/sample - loss: 0.1510 - acc: 0.9789 - val_loss: 0.2808 - val_acc: 0.9300\n",
      "Epoch 332/500\n",
      "900/900 [==============================] - 0s 137us/sample - loss: 0.1506 - acc: 0.9800 - val_loss: 0.2814 - val_acc: 0.9300\n",
      "Epoch 333/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.1502 - acc: 0.9800 - val_loss: 0.2807 - val_acc: 0.9300\n",
      "Epoch 334/500\n",
      "900/900 [==============================] - 0s 163us/sample - loss: 0.1499 - acc: 0.9800 - val_loss: 0.2801 - val_acc: 0.9300\n",
      "Epoch 335/500\n",
      "900/900 [==============================] - 0s 150us/sample - loss: 0.1495 - acc: 0.9800 - val_loss: 0.2800 - val_acc: 0.9300\n",
      "Epoch 336/500\n",
      "900/900 [==============================] - 0s 140us/sample - loss: 0.1492 - acc: 0.9811 - val_loss: 0.2815 - val_acc: 0.9300\n",
      "Epoch 337/500\n",
      "900/900 [==============================] - 0s 132us/sample - loss: 0.1489 - acc: 0.9800 - val_loss: 0.2811 - val_acc: 0.9300\n",
      "Epoch 338/500\n",
      "900/900 [==============================] - 0s 150us/sample - loss: 0.1485 - acc: 0.9800 - val_loss: 0.2802 - val_acc: 0.9400\n",
      "Epoch 339/500\n",
      "900/900 [==============================] - 0s 143us/sample - loss: 0.1482 - acc: 0.9833 - val_loss: 0.2795 - val_acc: 0.9400\n",
      "Epoch 340/500\n",
      "900/900 [==============================] - 0s 127us/sample - loss: 0.1478 - acc: 0.9833 - val_loss: 0.2783 - val_acc: 0.9400\n",
      "Epoch 341/500\n",
      "900/900 [==============================] - 0s 149us/sample - loss: 0.1475 - acc: 0.9833 - val_loss: 0.2784 - val_acc: 0.9400\n",
      "Epoch 342/500\n",
      "900/900 [==============================] - 0s 135us/sample - loss: 0.1471 - acc: 0.9833 - val_loss: 0.2778 - val_acc: 0.9400\n",
      "Epoch 343/500\n",
      "900/900 [==============================] - 0s 115us/sample - loss: 0.1468 - acc: 0.9833 - val_loss: 0.2776 - val_acc: 0.9400\n",
      "Epoch 344/500\n",
      "900/900 [==============================] - 0s 140us/sample - loss: 0.1464 - acc: 0.9833 - val_loss: 0.2775 - val_acc: 0.9400\n",
      "Epoch 345/500\n",
      "900/900 [==============================] - 0s 135us/sample - loss: 0.1461 - acc: 0.9833 - val_loss: 0.2773 - val_acc: 0.9400\n",
      "Epoch 346/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.1458 - acc: 0.9833 - val_loss: 0.2796 - val_acc: 0.9400\n",
      "Epoch 347/500\n",
      "900/900 [==============================] - 0s 146us/sample - loss: 0.1454 - acc: 0.9833 - val_loss: 0.2792 - val_acc: 0.9400\n",
      "Epoch 348/500\n",
      "900/900 [==============================] - 0s 140us/sample - loss: 0.1451 - acc: 0.9833 - val_loss: 0.2785 - val_acc: 0.9400\n",
      "Epoch 349/500\n",
      "900/900 [==============================] - 0s 169us/sample - loss: 0.1448 - acc: 0.9833 - val_loss: 0.2783 - val_acc: 0.9400\n",
      "Epoch 350/500\n",
      "900/900 [==============================] - 0s 158us/sample - loss: 0.1444 - acc: 0.9833 - val_loss: 0.2780 - val_acc: 0.9400\n",
      "Epoch 351/500\n",
      "900/900 [==============================] - 0s 153us/sample - loss: 0.1440 - acc: 0.9833 - val_loss: 0.2769 - val_acc: 0.9400\n",
      "Epoch 352/500\n",
      "900/900 [==============================] - 0s 162us/sample - loss: 0.1437 - acc: 0.9833 - val_loss: 0.2769 - val_acc: 0.9400\n",
      "Epoch 353/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 121us/sample - loss: 0.1434 - acc: 0.9833 - val_loss: 0.2764 - val_acc: 0.9400\n",
      "Epoch 354/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.1430 - acc: 0.9856 - val_loss: 0.2757 - val_acc: 0.9400\n",
      "Epoch 355/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.1427 - acc: 0.9856 - val_loss: 0.2737 - val_acc: 0.9400\n",
      "Epoch 356/500\n",
      "900/900 [==============================] - 0s 164us/sample - loss: 0.1423 - acc: 0.9856 - val_loss: 0.2757 - val_acc: 0.9400\n",
      "Epoch 357/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1420 - acc: 0.9856 - val_loss: 0.2752 - val_acc: 0.9400\n",
      "Epoch 358/500\n",
      "900/900 [==============================] - 0s 127us/sample - loss: 0.1416 - acc: 0.9856 - val_loss: 0.2745 - val_acc: 0.9400\n",
      "Epoch 359/500\n",
      "900/900 [==============================] - 0s 111us/sample - loss: 0.1413 - acc: 0.9856 - val_loss: 0.2742 - val_acc: 0.9400\n",
      "Epoch 360/500\n",
      "900/900 [==============================] - 0s 115us/sample - loss: 0.1410 - acc: 0.9856 - val_loss: 0.2761 - val_acc: 0.9300\n",
      "Epoch 361/500\n",
      "900/900 [==============================] - 0s 111us/sample - loss: 0.1407 - acc: 0.9856 - val_loss: 0.2754 - val_acc: 0.9300\n",
      "Epoch 362/500\n",
      "900/900 [==============================] - 0s 110us/sample - loss: 0.1403 - acc: 0.9856 - val_loss: 0.2749 - val_acc: 0.9400\n",
      "Epoch 363/500\n",
      "900/900 [==============================] - 0s 108us/sample - loss: 0.1400 - acc: 0.9856 - val_loss: 0.2746 - val_acc: 0.9400\n",
      "Epoch 364/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.1397 - acc: 0.9856 - val_loss: 0.2741 - val_acc: 0.9400\n",
      "Epoch 365/500\n",
      "900/900 [==============================] - 0s 160us/sample - loss: 0.1394 - acc: 0.9856 - val_loss: 0.2743 - val_acc: 0.9300\n",
      "Epoch 366/500\n",
      "900/900 [==============================] - 0s 121us/sample - loss: 0.1391 - acc: 0.9856 - val_loss: 0.2738 - val_acc: 0.9300\n",
      "Epoch 367/500\n",
      "900/900 [==============================] - 0s 139us/sample - loss: 0.1388 - acc: 0.9856 - val_loss: 0.2736 - val_acc: 0.9300\n",
      "Epoch 368/500\n",
      "900/900 [==============================] - 0s 134us/sample - loss: 0.1385 - acc: 0.9856 - val_loss: 0.2728 - val_acc: 0.9400\n",
      "Epoch 369/500\n",
      "900/900 [==============================] - 0s 121us/sample - loss: 0.1381 - acc: 0.9856 - val_loss: 0.2728 - val_acc: 0.9300\n",
      "Epoch 370/500\n",
      "900/900 [==============================] - 0s 148us/sample - loss: 0.1378 - acc: 0.9856 - val_loss: 0.2729 - val_acc: 0.9300\n",
      "Epoch 371/500\n",
      "900/900 [==============================] - 0s 111us/sample - loss: 0.1376 - acc: 0.9856 - val_loss: 0.2723 - val_acc: 0.9300\n",
      "Epoch 372/500\n",
      "900/900 [==============================] - 0s 123us/sample - loss: 0.1373 - acc: 0.9856 - val_loss: 0.2717 - val_acc: 0.9300\n",
      "Epoch 373/500\n",
      "900/900 [==============================] - 0s 136us/sample - loss: 0.1369 - acc: 0.9856 - val_loss: 0.2731 - val_acc: 0.9300\n",
      "Epoch 374/500\n",
      "900/900 [==============================] - 0s 140us/sample - loss: 0.1366 - acc: 0.9856 - val_loss: 0.2720 - val_acc: 0.9300\n",
      "Epoch 375/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.1363 - acc: 0.9856 - val_loss: 0.2706 - val_acc: 0.9400\n",
      "Epoch 376/500\n",
      "900/900 [==============================] - 0s 143us/sample - loss: 0.1361 - acc: 0.9856 - val_loss: 0.2694 - val_acc: 0.9400\n",
      "Epoch 377/500\n",
      "900/900 [==============================] - 0s 139us/sample - loss: 0.1357 - acc: 0.9856 - val_loss: 0.2664 - val_acc: 0.9400\n",
      "Epoch 378/500\n",
      "900/900 [==============================] - 0s 112us/sample - loss: 0.1355 - acc: 0.9856 - val_loss: 0.2667 - val_acc: 0.9400\n",
      "Epoch 379/500\n",
      "900/900 [==============================] - 0s 130us/sample - loss: 0.1351 - acc: 0.9856 - val_loss: 0.2670 - val_acc: 0.9400\n",
      "Epoch 380/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1348 - acc: 0.9856 - val_loss: 0.2669 - val_acc: 0.9400\n",
      "Epoch 381/500\n",
      "900/900 [==============================] - 0s 144us/sample - loss: 0.1345 - acc: 0.9856 - val_loss: 0.2670 - val_acc: 0.9400\n",
      "Epoch 382/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.1342 - acc: 0.9856 - val_loss: 0.2674 - val_acc: 0.9400\n",
      "Epoch 383/500\n",
      "900/900 [==============================] - 0s 118us/sample - loss: 0.1339 - acc: 0.9856 - val_loss: 0.2674 - val_acc: 0.9300\n",
      "Epoch 384/500\n",
      "900/900 [==============================] - 0s 130us/sample - loss: 0.1336 - acc: 0.9856 - val_loss: 0.2675 - val_acc: 0.9300\n",
      "Epoch 385/500\n",
      "900/900 [==============================] - 0s 167us/sample - loss: 0.1333 - acc: 0.9856 - val_loss: 0.2673 - val_acc: 0.9300\n",
      "Epoch 386/500\n",
      "900/900 [==============================] - 0s 135us/sample - loss: 0.1331 - acc: 0.9856 - val_loss: 0.2686 - val_acc: 0.9300\n",
      "Epoch 387/500\n",
      "900/900 [==============================] - 0s 133us/sample - loss: 0.1328 - acc: 0.9856 - val_loss: 0.2684 - val_acc: 0.9300\n",
      "Epoch 388/500\n",
      "900/900 [==============================] - 0s 150us/sample - loss: 0.1325 - acc: 0.9856 - val_loss: 0.2680 - val_acc: 0.9300\n",
      "Epoch 389/500\n",
      "900/900 [==============================] - 0s 147us/sample - loss: 0.1322 - acc: 0.9856 - val_loss: 0.2667 - val_acc: 0.9300\n",
      "Epoch 390/500\n",
      "900/900 [==============================] - 0s 153us/sample - loss: 0.1319 - acc: 0.9856 - val_loss: 0.2666 - val_acc: 0.9300\n",
      "Epoch 391/500\n",
      "900/900 [==============================] - 0s 143us/sample - loss: 0.1316 - acc: 0.9856 - val_loss: 0.2656 - val_acc: 0.9300\n",
      "Epoch 392/500\n",
      "900/900 [==============================] - 0s 148us/sample - loss: 0.1313 - acc: 0.9856 - val_loss: 0.2660 - val_acc: 0.9300\n",
      "Epoch 393/500\n",
      "900/900 [==============================] - 0s 140us/sample - loss: 0.1310 - acc: 0.9856 - val_loss: 0.2652 - val_acc: 0.9300\n",
      "Epoch 394/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.1307 - acc: 0.9867 - val_loss: 0.2653 - val_acc: 0.9300\n",
      "Epoch 395/500\n",
      "900/900 [==============================] - 0s 144us/sample - loss: 0.1305 - acc: 0.9856 - val_loss: 0.2656 - val_acc: 0.9300\n",
      "Epoch 396/500\n",
      "900/900 [==============================] - 0s 132us/sample - loss: 0.1301 - acc: 0.9900 - val_loss: 0.2646 - val_acc: 0.9300\n",
      "Epoch 397/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.1299 - acc: 0.9867 - val_loss: 0.2633 - val_acc: 0.9300\n",
      "Epoch 398/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.1296 - acc: 0.9856 - val_loss: 0.2638 - val_acc: 0.9300\n",
      "Epoch 399/500\n",
      "900/900 [==============================] - 0s 149us/sample - loss: 0.1293 - acc: 0.9856 - val_loss: 0.2641 - val_acc: 0.9300\n",
      "Epoch 400/500\n",
      "900/900 [==============================] - 0s 150us/sample - loss: 0.1290 - acc: 0.9856 - val_loss: 0.2657 - val_acc: 0.9300\n",
      "Epoch 401/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.1287 - acc: 0.9889 - val_loss: 0.2656 - val_acc: 0.9300\n",
      "Epoch 402/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.1284 - acc: 0.9900 - val_loss: 0.2657 - val_acc: 0.9300\n",
      "Epoch 403/500\n",
      "900/900 [==============================] - 0s 158us/sample - loss: 0.1282 - acc: 0.9900 - val_loss: 0.2651 - val_acc: 0.9300\n",
      "Epoch 404/500\n",
      "900/900 [==============================] - 0s 154us/sample - loss: 0.1279 - acc: 0.9900 - val_loss: 0.2649 - val_acc: 0.9300\n",
      "Epoch 405/500\n",
      "900/900 [==============================] - 0s 162us/sample - loss: 0.1276 - acc: 0.9900 - val_loss: 0.2648 - val_acc: 0.9300\n",
      "Epoch 406/500\n",
      "900/900 [==============================] - 0s 162us/sample - loss: 0.1273 - acc: 0.9900 - val_loss: 0.2646 - val_acc: 0.9300\n",
      "Epoch 407/500\n",
      "900/900 [==============================] - 0s 167us/sample - loss: 0.1271 - acc: 0.9900 - val_loss: 0.2662 - val_acc: 0.9300\n",
      "Epoch 408/500\n",
      "900/900 [==============================] - 0s 121us/sample - loss: 0.1268 - acc: 0.9900 - val_loss: 0.2659 - val_acc: 0.9300\n",
      "Epoch 409/500\n",
      "900/900 [==============================] - 0s 141us/sample - loss: 0.1265 - acc: 0.9900 - val_loss: 0.2658 - val_acc: 0.9300\n",
      "Epoch 410/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.1262 - acc: 0.9900 - val_loss: 0.2656 - val_acc: 0.9300\n",
      "Epoch 411/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.1260 - acc: 0.9900 - val_loss: 0.2650 - val_acc: 0.9300\n",
      "Epoch 412/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 155us/sample - loss: 0.1257 - acc: 0.9911 - val_loss: 0.2641 - val_acc: 0.9300\n",
      "Epoch 413/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.1254 - acc: 0.9900 - val_loss: 0.2639 - val_acc: 0.9300\n",
      "Epoch 414/500\n",
      "900/900 [==============================] - 0s 143us/sample - loss: 0.1252 - acc: 0.9900 - val_loss: 0.2647 - val_acc: 0.9300\n",
      "Epoch 415/500\n",
      "900/900 [==============================] - 0s 147us/sample - loss: 0.1249 - acc: 0.9900 - val_loss: 0.2642 - val_acc: 0.9300\n",
      "Epoch 416/500\n",
      "900/900 [==============================] - 0s 119us/sample - loss: 0.1246 - acc: 0.9900 - val_loss: 0.2640 - val_acc: 0.9300\n",
      "Epoch 417/500\n",
      "900/900 [==============================] - 0s 135us/sample - loss: 0.1243 - acc: 0.9900 - val_loss: 0.2628 - val_acc: 0.9300\n",
      "Epoch 418/500\n",
      "900/900 [==============================] - 0s 126us/sample - loss: 0.1241 - acc: 0.9900 - val_loss: 0.2625 - val_acc: 0.9300\n",
      "Epoch 419/500\n",
      "900/900 [==============================] - 0s 120us/sample - loss: 0.1238 - acc: 0.9900 - val_loss: 0.2627 - val_acc: 0.9300\n",
      "Epoch 420/500\n",
      "900/900 [==============================] - 0s 137us/sample - loss: 0.1235 - acc: 0.9911 - val_loss: 0.2625 - val_acc: 0.9300\n",
      "Epoch 421/500\n",
      "900/900 [==============================] - 0s 137us/sample - loss: 0.1233 - acc: 0.9911 - val_loss: 0.2627 - val_acc: 0.9300\n",
      "Epoch 422/500\n",
      "900/900 [==============================] - 0s 137us/sample - loss: 0.1230 - acc: 0.9911 - val_loss: 0.2627 - val_acc: 0.9300\n",
      "Epoch 423/500\n",
      "900/900 [==============================] - 0s 107us/sample - loss: 0.1228 - acc: 0.9911 - val_loss: 0.2621 - val_acc: 0.9300\n",
      "Epoch 424/500\n",
      "900/900 [==============================] - 0s 98us/sample - loss: 0.1225 - acc: 0.9911 - val_loss: 0.2618 - val_acc: 0.9300\n",
      "Epoch 425/500\n",
      "900/900 [==============================] - 0s 107us/sample - loss: 0.1223 - acc: 0.9911 - val_loss: 0.2619 - val_acc: 0.9300\n",
      "Epoch 426/500\n",
      "900/900 [==============================] - 0s 108us/sample - loss: 0.1220 - acc: 0.9911 - val_loss: 0.2634 - val_acc: 0.9300\n",
      "Epoch 427/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1218 - acc: 0.9911 - val_loss: 0.2630 - val_acc: 0.9300\n",
      "Epoch 428/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.1215 - acc: 0.9900 - val_loss: 0.2609 - val_acc: 0.9300\n",
      "Epoch 429/500\n",
      "900/900 [==============================] - 0s 162us/sample - loss: 0.1212 - acc: 0.9911 - val_loss: 0.2608 - val_acc: 0.9300\n",
      "Epoch 430/500\n",
      "900/900 [==============================] - 0s 120us/sample - loss: 0.1210 - acc: 0.9911 - val_loss: 0.2605 - val_acc: 0.9300\n",
      "Epoch 431/500\n",
      "900/900 [==============================] - 0s 135us/sample - loss: 0.1207 - acc: 0.9911 - val_loss: 0.2606 - val_acc: 0.9300\n",
      "Epoch 432/500\n",
      "900/900 [==============================] - 0s 136us/sample - loss: 0.1205 - acc: 0.9911 - val_loss: 0.2603 - val_acc: 0.9300\n",
      "Epoch 433/500\n",
      "900/900 [==============================] - 0s 134us/sample - loss: 0.1202 - acc: 0.9911 - val_loss: 0.2602 - val_acc: 0.9300\n",
      "Epoch 434/500\n",
      "900/900 [==============================] - 0s 121us/sample - loss: 0.1200 - acc: 0.9911 - val_loss: 0.2598 - val_acc: 0.9300\n",
      "Epoch 435/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.1197 - acc: 0.9911 - val_loss: 0.2598 - val_acc: 0.9300\n",
      "Epoch 436/500\n",
      "900/900 [==============================] - 0s 145us/sample - loss: 0.1195 - acc: 0.9911 - val_loss: 0.2589 - val_acc: 0.9300\n",
      "Epoch 437/500\n",
      "900/900 [==============================] - 0s 138us/sample - loss: 0.1192 - acc: 0.9911 - val_loss: 0.2587 - val_acc: 0.9300\n",
      "Epoch 438/500\n",
      "900/900 [==============================] - 0s 142us/sample - loss: 0.1190 - acc: 0.9911 - val_loss: 0.2554 - val_acc: 0.9300\n",
      "Epoch 439/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1187 - acc: 0.9911 - val_loss: 0.2559 - val_acc: 0.9300\n",
      "Epoch 440/500\n",
      "900/900 [==============================] - 0s 116us/sample - loss: 0.1185 - acc: 0.9911 - val_loss: 0.2564 - val_acc: 0.9300\n",
      "Epoch 441/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.1183 - acc: 0.9911 - val_loss: 0.2565 - val_acc: 0.9300\n",
      "Epoch 442/500\n",
      "900/900 [==============================] - 0s 111us/sample - loss: 0.1180 - acc: 0.9911 - val_loss: 0.2569 - val_acc: 0.9300\n",
      "Epoch 443/500\n",
      "900/900 [==============================] - 0s 154us/sample - loss: 0.1177 - acc: 0.9911 - val_loss: 0.2569 - val_acc: 0.9300\n",
      "Epoch 444/500\n",
      "900/900 [==============================] - 0s 155us/sample - loss: 0.1175 - acc: 0.9911 - val_loss: 0.2571 - val_acc: 0.9300\n",
      "Epoch 445/500\n",
      "900/900 [==============================] - 0s 135us/sample - loss: 0.1173 - acc: 0.9911 - val_loss: 0.2569 - val_acc: 0.9300\n",
      "Epoch 446/500\n",
      "900/900 [==============================] - 0s 140us/sample - loss: 0.1170 - acc: 0.9911 - val_loss: 0.2569 - val_acc: 0.9300\n",
      "Epoch 447/500\n",
      "900/900 [==============================] - 0s 134us/sample - loss: 0.1168 - acc: 0.9911 - val_loss: 0.2556 - val_acc: 0.9300\n",
      "Epoch 448/500\n",
      "900/900 [==============================] - 0s 149us/sample - loss: 0.1166 - acc: 0.9911 - val_loss: 0.2557 - val_acc: 0.9300\n",
      "Epoch 449/500\n",
      "900/900 [==============================] - 0s 156us/sample - loss: 0.1163 - acc: 0.9911 - val_loss: 0.2556 - val_acc: 0.9300\n",
      "Epoch 450/500\n",
      "900/900 [==============================] - 0s 118us/sample - loss: 0.1161 - acc: 0.9911 - val_loss: 0.2561 - val_acc: 0.9300\n",
      "Epoch 451/500\n",
      "900/900 [==============================] - 0s 130us/sample - loss: 0.1158 - acc: 0.9911 - val_loss: 0.2533 - val_acc: 0.9300\n",
      "Epoch 452/500\n",
      "900/900 [==============================] - 0s 128us/sample - loss: 0.1157 - acc: 0.9911 - val_loss: 0.2535 - val_acc: 0.9200\n",
      "Epoch 453/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.1154 - acc: 0.9911 - val_loss: 0.2541 - val_acc: 0.9200\n",
      "Epoch 454/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.1152 - acc: 0.9911 - val_loss: 0.2547 - val_acc: 0.9200\n",
      "Epoch 455/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.1149 - acc: 0.9911 - val_loss: 0.2546 - val_acc: 0.9200\n",
      "Epoch 456/500\n",
      "900/900 [==============================] - 0s 122us/sample - loss: 0.1147 - acc: 0.9911 - val_loss: 0.2548 - val_acc: 0.9200\n",
      "Epoch 457/500\n",
      "900/900 [==============================] - 0s 117us/sample - loss: 0.1144 - acc: 0.9911 - val_loss: 0.2522 - val_acc: 0.9200\n",
      "Epoch 458/500\n",
      "900/900 [==============================] - 0s 109us/sample - loss: 0.1142 - acc: 0.9911 - val_loss: 0.2535 - val_acc: 0.9200\n",
      "Epoch 459/500\n",
      "900/900 [==============================] - 0s 118us/sample - loss: 0.1140 - acc: 0.9911 - val_loss: 0.2534 - val_acc: 0.9200\n",
      "Epoch 460/500\n",
      "900/900 [==============================] - 0s 138us/sample - loss: 0.1138 - acc: 0.9911 - val_loss: 0.2542 - val_acc: 0.9200\n",
      "Epoch 461/500\n",
      "900/900 [==============================] - 0s 138us/sample - loss: 0.1135 - acc: 0.9911 - val_loss: 0.2542 - val_acc: 0.9200\n",
      "Epoch 462/500\n",
      "900/900 [==============================] - 0s 125us/sample - loss: 0.1133 - acc: 0.9911 - val_loss: 0.2547 - val_acc: 0.9200\n",
      "Epoch 463/500\n",
      "900/900 [==============================] - 0s 154us/sample - loss: 0.1131 - acc: 0.9911 - val_loss: 0.2595 - val_acc: 0.9200\n",
      "Epoch 464/500\n",
      "900/900 [==============================] - 0s 143us/sample - loss: 0.1129 - acc: 0.9922 - val_loss: 0.2587 - val_acc: 0.9200\n",
      "Epoch 465/500\n",
      "900/900 [==============================] - 0s 152us/sample - loss: 0.1126 - acc: 0.9922 - val_loss: 0.2579 - val_acc: 0.9200\n",
      "Epoch 466/500\n",
      "900/900 [==============================] - 0s 160us/sample - loss: 0.1124 - acc: 0.9922 - val_loss: 0.2574 - val_acc: 0.9200\n",
      "Epoch 467/500\n",
      "900/900 [==============================] - 0s 137us/sample - loss: 0.1121 - acc: 0.9922 - val_loss: 0.2573 - val_acc: 0.9200\n",
      "Epoch 468/500\n",
      "900/900 [==============================] - 0s 139us/sample - loss: 0.1119 - acc: 0.9922 - val_loss: 0.2572 - val_acc: 0.9200\n",
      "Epoch 469/500\n",
      "900/900 [==============================] - 0s 140us/sample - loss: 0.1117 - acc: 0.9922 - val_loss: 0.2538 - val_acc: 0.9200\n",
      "Epoch 470/500\n",
      "900/900 [==============================] - 0s 124us/sample - loss: 0.1117 - acc: 0.9911 - val_loss: 0.2546 - val_acc: 0.9200\n",
      "Epoch 471/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 129us/sample - loss: 0.1114 - acc: 0.9922 - val_loss: 0.2541 - val_acc: 0.9200\n",
      "Epoch 472/500\n",
      "900/900 [==============================] - 0s 121us/sample - loss: 0.1111 - acc: 0.9922 - val_loss: 0.2549 - val_acc: 0.9200\n",
      "Epoch 473/500\n",
      "900/900 [==============================] - 0s 98us/sample - loss: 0.1109 - acc: 0.9922 - val_loss: 0.2552 - val_acc: 0.9200\n",
      "Epoch 474/500\n",
      "900/900 [==============================] - 0s 104us/sample - loss: 0.1106 - acc: 0.9922 - val_loss: 0.2554 - val_acc: 0.9200\n",
      "Epoch 475/500\n",
      "900/900 [==============================] - 0s 112us/sample - loss: 0.1104 - acc: 0.9922 - val_loss: 0.2557 - val_acc: 0.9200\n",
      "Epoch 476/500\n",
      "900/900 [==============================] - 0s 139us/sample - loss: 0.1102 - acc: 0.9922 - val_loss: 0.2550 - val_acc: 0.9200\n",
      "Epoch 477/500\n",
      "900/900 [==============================] - 0s 119us/sample - loss: 0.1100 - acc: 0.9922 - val_loss: 0.2550 - val_acc: 0.9200\n",
      "Epoch 478/500\n",
      "900/900 [==============================] - 0s 112us/sample - loss: 0.1097 - acc: 0.9922 - val_loss: 0.2550 - val_acc: 0.9200\n",
      "Epoch 479/500\n",
      "900/900 [==============================] - 0s 114us/sample - loss: 0.1095 - acc: 0.9922 - val_loss: 0.2551 - val_acc: 0.9200\n",
      "Epoch 480/500\n",
      "900/900 [==============================] - 0s 125us/sample - loss: 0.1093 - acc: 0.9922 - val_loss: 0.2550 - val_acc: 0.9200\n",
      "Epoch 481/500\n",
      "900/900 [==============================] - 0s 115us/sample - loss: 0.1091 - acc: 0.9922 - val_loss: 0.2551 - val_acc: 0.9200\n",
      "Epoch 482/500\n",
      "900/900 [==============================] - 0s 112us/sample - loss: 0.1089 - acc: 0.9922 - val_loss: 0.2521 - val_acc: 0.9200\n",
      "Epoch 483/500\n",
      "900/900 [==============================] - 0s 119us/sample - loss: 0.1089 - acc: 0.9922 - val_loss: 0.2532 - val_acc: 0.9200\n",
      "Epoch 484/500\n",
      "900/900 [==============================] - 0s 120us/sample - loss: 0.1086 - acc: 0.9922 - val_loss: 0.2539 - val_acc: 0.9200\n",
      "Epoch 485/500\n",
      "900/900 [==============================] - 0s 129us/sample - loss: 0.1084 - acc: 0.9922 - val_loss: 0.2545 - val_acc: 0.9200\n",
      "Epoch 486/500\n",
      "900/900 [==============================] - 0s 112us/sample - loss: 0.1081 - acc: 0.9922 - val_loss: 0.2562 - val_acc: 0.9200\n",
      "Epoch 487/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.1078 - acc: 0.9922 - val_loss: 0.2552 - val_acc: 0.9200\n",
      "Epoch 488/500\n",
      "900/900 [==============================] - 0s 127us/sample - loss: 0.1076 - acc: 0.9922 - val_loss: 0.2596 - val_acc: 0.9100\n",
      "Epoch 489/500\n",
      "900/900 [==============================] - 0s 133us/sample - loss: 0.1074 - acc: 0.9922 - val_loss: 0.2591 - val_acc: 0.9100\n",
      "Epoch 490/500\n",
      "900/900 [==============================] - 0s 122us/sample - loss: 0.1072 - acc: 0.9922 - val_loss: 0.2585 - val_acc: 0.9200\n",
      "Epoch 491/500\n",
      "900/900 [==============================] - 0s 91us/sample - loss: 0.1070 - acc: 0.9922 - val_loss: 0.2585 - val_acc: 0.9100\n",
      "Epoch 492/500\n",
      "900/900 [==============================] - 0s 98us/sample - loss: 0.1068 - acc: 0.9922 - val_loss: 0.2599 - val_acc: 0.9100\n",
      "Epoch 493/500\n",
      "900/900 [==============================] - 0s 109us/sample - loss: 0.1066 - acc: 0.9922 - val_loss: 0.2612 - val_acc: 0.9100\n",
      "Epoch 494/500\n",
      "900/900 [==============================] - 0s 115us/sample - loss: 0.1063 - acc: 0.9922 - val_loss: 0.2604 - val_acc: 0.9100\n",
      "Epoch 495/500\n",
      "900/900 [==============================] - 0s 113us/sample - loss: 0.1061 - acc: 0.9922 - val_loss: 0.2598 - val_acc: 0.9100\n",
      "Epoch 496/500\n",
      "900/900 [==============================] - 0s 120us/sample - loss: 0.1059 - acc: 0.9922 - val_loss: 0.2591 - val_acc: 0.9200\n",
      "Epoch 497/500\n",
      "900/900 [==============================] - 0s 115us/sample - loss: 0.1057 - acc: 0.9922 - val_loss: 0.2597 - val_acc: 0.9100\n",
      "Epoch 498/500\n",
      "900/900 [==============================] - 0s 139us/sample - loss: 0.1055 - acc: 0.9922 - val_loss: 0.2599 - val_acc: 0.9100\n",
      "Epoch 499/500\n",
      "900/900 [==============================] - 0s 131us/sample - loss: 0.1053 - acc: 0.9922 - val_loss: 0.2593 - val_acc: 0.9100\n",
      "Epoch 500/500\n",
      "900/900 [==============================] - 0s 122us/sample - loss: 0.1051 - acc: 0.9922 - val_loss: 0.2588 - val_acc: 0.9100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc: 0.99222225\n",
      "Test acc: 0.91\n"
     ]
    }
   ],
   "source": [
    "print(\"Training acc:\", acc[-1])\n",
    "print(\"Test acc:\", val_acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and validation loss')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs=range(len(acc)) \n",
    "\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', \"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation loss\")\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percision and Recall Approach\n",
    "* Here is the precision and recall formula:\n",
    "\n",
    "![image of formula](./plots/precision_recall.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redeclaring X , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (256326, 29)\n",
      "y train shape: (256326,)\n",
      "\n",
      "X test shape: (28481, 29)\n",
      "y test shape: (28481,)\n"
     ]
    }
   ],
   "source": [
    "Data = df.to_numpy()\n",
    "\n",
    "train_test_ratio = 0.9\n",
    "\n",
    "random.shuffle(Data)\n",
    "\n",
    "X = Data[:, :-1]\n",
    "y = Data[:, -1]\n",
    "\n",
    "x_train = X[:math.floor(train_test_ratio * len(X))]\n",
    "y_train = y[:math.floor(train_test_ratio * len(y))]\n",
    "\n",
    "x_test = X[math.floor(train_test_ratio * len(X)):]\n",
    "y_test = y[math.floor(train_test_ratio * len(y)):]\n",
    "\n",
    "print(\"X train shape:\", x_train.shape)\n",
    "print(\"y train shape:\", y_train.shape)\n",
    "print()\n",
    "print(\"X test shape:\", x_test.shape)\n",
    "print(\"y test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_clf = LogisticRegression(verbose=1, penalty='l2', max_iter=500, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    }
   ],
   "source": [
    "history = logistic_regression_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = logistic_regression_clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Precision-Recall vs Threshold Chart\")\n",
    "plt.plot(thresholds, precisions[: -1], \"b--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recalls[: -1], \"r--\", label=\"Recall\")\n",
    "plt.ylabel(\"Precision, Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_F1_scores(precisions, recalls):\n",
    "    assert len(precisions) == len(recalls)\n",
    "    F1_scores = []\n",
    "    for i in range(len(precisions)):\n",
    "        F1_score = 2 * (precisions[i] * recalls[i]) / (precisions[i] + recalls[i])\n",
    "        F1_scores.append(F1_score)\n",
    "    return np.asarray(F1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_F1_scores(precisions, recalls):\n",
    "    F1_score = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    return F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_scores = compute_F1_scores(precisions, recalls)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(F1_scores, label='F1 score')\n",
    "plt.title(\"F1 score with precisions and recalls\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.xlabel(\"precisions, recalls\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_F1_score_index = F1_scores.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum F1 score: 0.6465\n",
      "Properties:\n",
      "\tPercision: 0.7619\n",
      "\tRecall:    1\n",
      "\tThreshold: 0.192877\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum F1 score: %.4f\" % F1_scores[max_F1_score_index])\n",
    "print(\"Properties:\\n\\tPercision: %.4f\\n\\tRecall: %4.f\\n\\tThreshold: %f\" % (precisions[max_F1_score_index], recalls[max_F1_score_index], thresholds[max_F1_score_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression_clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected threshold: 0.19287650708148127\n"
     ]
    }
   ],
   "source": [
    "selected_threshold = thresholds[max_F1_score_index]\n",
    "print(\"Selected threshold:\", selected_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = classify(y_pred[:, 1], selected_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Logistic Regression] --> Accuracy over validation set: 0.9987711105649381\n"
     ]
    }
   ],
   "source": [
    "true_guesses = np.sum(y_predict == y_test)\n",
    "accuracy_over_validation_set = true_guesses / len(y_test)\n",
    "print(\"[Logistic Regression] --> Accuracy over validation set:\", accuracy_over_validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_predict)\n",
    "recall = recall_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision value: 0.7619047619047619\n",
      "Recall value: 0.5614035087719298\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision value:\", precision)\n",
    "print(\"Recall value:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_score = compute_single_F1_scores(precisions=precision, recalls=recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of predicted probability is 0.646465\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score of predicted probability is %.6f\" % F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
